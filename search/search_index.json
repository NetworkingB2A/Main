{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"markdown_tips/","title":"Markdown tips","text":"<p>good documentation for a README file</p> <p>Example is stronghold project</p> <p>logo, name of project badges. quick one liner about the project/app/. What is this? Key features usage install configuration (if any) How to contribute Acknowledgements  donations</p> <ul> <li>1. Section</li> <li>1.1. Section<ul> <li>1.1.1. Section</li> </ul> </li> <li>2. Section</li> <li>2.1. Section</li> <li>2.2. Section</li> </ul>"},{"location":"markdown_tips/#1-section","title":"1. Section","text":"<p>this is the first section</p>"},{"location":"markdown_tips/#11-section","title":"1.1. Section","text":"<p>This is an important section</p>"},{"location":"markdown_tips/#111-section","title":"1.1.1. Section","text":"<p>this is the lowest level section on this page.</p>"},{"location":"markdown_tips/#2-section","title":"2. Section","text":"<p>this is the root section for this page.</p>"},{"location":"markdown_tips/#21-section","title":"2.1. Section","text":"<p>This is another section.</p>"},{"location":"markdown_tips/#22-section","title":"2.2. Section","text":"<p>this section is a section which also happens to be a section.</p> <p>this test is to see bolding - [x] to do - [ ] to do - [x] to do - [ ] to do</p> left center right 1 2 3 4 5 6 7 8 9"},{"location":"Ansible/Ansible%20Modules/","title":"Ansible Modules","text":"<p>creating custom modules.</p> <p>in order to create a custom module, you need to create a custom python script. BEST PRACTICE is to create documentation as well and examples. so you can use the <code>ansible-doc {module-name}</code> command. This documentation file is created under a modules_utils directory where as the code itself would be stored under the modules directory. one example /usr/lib/python3/dist-packages/ansible/modules/ and /usr/lib/python3/dist-packages/ansible/modules_utils/</p>"},{"location":"Ansible/Ansible%20Training/","title":"Ansible Training","text":"<p>quick note</p> <p>use greater than symbol ansible with items ansible-playbook playbook --list-host</p>"},{"location":"Ansible/Ansible%20Training/#training-ansible","title":"Training Ansible","text":"<p>Create a python virtual environment.</p> <p><code>python3 -m venv venv</code></p> <p>Switch to environment.</p> <p><code> source venv/bin/active </code></p> <p>install ansible</p> <p><code>pip install ansible</code></p>"},{"location":"Ansible/Ansible%20Training/#need-to-know-commands-for-ansible","title":"Need to know commands for Ansible","text":"<p>view info about your ansible</p> <pre><code>ansible --version\n</code></pre> <p>Output</p> <pre><code>\n*ansible [core 2.11.2]\n\n    config file = /etc/ansible/ansible.cfg\n    configured module search path = ['/home/angella/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']\n    ansible python module location = /home/angella/Programming/Infrastructure-as-Code/venv/lib/python3.8/site-packages/ansible\n    ansible collection location = /home/angella/.ansible/collections:/usr/share/ansible/collections\n    executable location = /home/angella/Programming/Infrastructure-as-Code/venv/bin/ansible\n    python version = 3.8.10 (default, Jun  2 2021, 10:49:15) [GCC 10.3.0]\n    jinja version = 3.0.1\n    libyaml = True\n</code></pre>"},{"location":"Ansible/Ansible%20Training/#good-to-know","title":"Good to know","text":"<p>Functions of Ansible - Application Deployment - Multi-tier Orchestration - Configuration Management - Provisioning - CICD Pipeline</p> <p>Parts of Ansible  - Playbook   - Written in YAML   - Tasks are executed sequentially   - uses Ansible Modules   - plays are ordered sets of tasks to execute against host selection from your inventory   - a playbook is a file containing one or more plays.  - Modules   - Bit of code/Tools in your toolkit   - python, powershell, or any language    - You don't know to know how it work, just how to structure the task you give it   - You can go on Ansible website and find the whole list of modules   - SIDE NOTE     - Sometime you make need to use runtime command modules that just pass commands to the devices     - Examples are Shell, command, Raw (use if no python is on the end device) and scripts - Inventory   - Can come from a lot of different places   - you can use your own CMDB - Plugins ( I dont fully understand yet...)   - python api   - code that plugs into the core engine  </p> <p>You can run the following to check you syntax <code> ansible-playbook {Playbook name} --syntax-check </code></p>"},{"location":"Ansible/Ansible%20Training/#ansible-keywords","title":"Ansible Keywords","text":"<ul> <li>to_nice_json</li> </ul>"},{"location":"Ansible/Ansible%20Training/#best-practices","title":"Best practices","text":"<ul> <li>if you put more then one playbook into a file, those playbooks should be related.</li> </ul>"},{"location":"Ansible/Ansible%20Training/#other-notes","title":"Other notes","text":"<ul> <li>play level should be above the tasks</li> <li>you can run one task at a time if you would like to test out something. this can be done via command line.</li> <li>Plug in changes the data</li> </ul>"},{"location":"Ansible/Ansible%20Training/#questions","title":"Questions","text":"<p>When would you use Jinja Templating vs the cisco IOS module? - you would use both. the power of a template is that you can update the task in one spot and have logic built into the template that you cant build into the task. - seems like the best idea would be to use jinja template as you main config.</p> <p>What is the best method for Idempotency and hashed/encrypted config? example a secret username on a cisco device( password is encrypted)</p> <p>What is the best method for ACL where a cisco devices does not keep the ACL in the order you want it to? Example is a standard ACL moves remarks and host ip address around.</p> <p>What is the best idea for having your custom Ansible config file? Issue. when I run a playbook from a different folder it uses that the default config file instead of the  - If you place an Ansible config file in your directory you are currently in. That will become your new Ansible config. If you don't put the Ansible config file in the directory you are in, the default will be in  /etc/ansible/ansible.cfg</p> <p>is it best to use different role based on different switches - IE one role for ios vs nexus?</p> <p>What is a meta tag?</p>"},{"location":"Ansible/Ansible%20Training/#variables","title":"Variables","text":"<p>vars is a Keyword inside of ansible that you can create variables. you can use the vars keyword inside a playbook, inventory file, tasks, ect.</p> <p>What is the highest precedence for Ansible vars 1. Extra Vars 2. Task Vars 3. Block Vars 4. Role and Included vars 5. Play var_files 6. Play Var_prompt 7. Play vars 8. Set_facts 9. Registered Vars 10. Host facts 11. Playbook host_vars 12. Playbook group_vars 13. Inventory host_vars 14. Inventory group_vars 15. Inventory vars 16. Role defaults</p>"},{"location":"Ansible/Ansible%20Training/#task-types","title":"task types","text":"<p>Normal tasks - They will run sequentially Handler tasks - Handlers are special tasks that run at the end of a play if notified by another task. - if a configuration file get changed notify a service restart task it needs to run - They will only run once at the end of a play. no matter how many times they have been triggered - See bottom for an example</p>"},{"location":"Ansible/Ansible%20Training/#loops","title":"Loops","text":"<ul> <li>easiest way is {{ item }} then with_items: and list of items </li> <li>see code below</li> </ul>"},{"location":"Ansible/Ansible%20Training/#roles","title":"Roles","text":"<p>structure of a role directory you can create this by hand or with the ansible galaxy command</p> <pre><code>mkdir roles\ncd roles/\nansible-galaxy init {role name}\n</code></pre> <p>roles/   common/     files/     templates/     tasks/     handlers/     vars/     defaults/     meta/   switch/     files/     templates/     tasks/     handlers/     vars/     defaults/     meta/</p> <p>Common is for all if your devices, generally  this is true. you can create different tasks inside your role but Ansible will not pick them up by default. You will need to create a task, give it a unique name. Then in the main.yml task include any task you want and preform and include of the uniquely named yaml files.</p> <p>Tips for using quotes in playbooks\\tasks 1. if I have Jinja variable(eg {{ Variable_name }}) at the beginning or end of the line; otherwise YAML will parse the line as nested objects due to the braces. 2. If there are any colons in the string. (eg in urls)</p> <p>NOTES By default, ansible will stop all playbook execution when a task fails, and won't notify any handlers that may need to be triggered. In some cases, this leads to unintended side effects. If you want to make sure handlers always run after a task use notify to call the handler, if the playbook fails, add --force-handlers to your ansible-playbook command.</p>"},{"location":"Ansible/Ansible%20Training/#how-to-call-a-role-from-a-playbook","title":"how to call a role from a playbook","text":"<ul> <li>hosts: switches   roles:<ul> <li>common</li> <li>switch</li> </ul> </li> </ul> <p>Ansible must know - register - changed_when: false</p>"},{"location":"Ansible/Ansible%20Training/#handler-example","title":"Handler example","text":"<p><code> tasks:   - name: add cache dir         file:       path: /opt/cache       state: directory   - name:install nginx     yum:       name: nginx       state: latest     notify: restart nginx <p>handlers:   - name: restart nginx     service:       name: nginx       state: restart </p> <p></p>"},{"location":"Ansible/Ansible%20Training/#loop-example","title":"Loop example","text":"<p>Basic <code> - name: install python bindings for SELinux   yum: name={{item}} state=present   with_items:   - libselinux-python   - libsemanage-python </code></p> <p>Slightly more advanced <code> - name: Default config   include_tasks: '{{ defaultconfigtasks }}'   loop:     - ../tasks/ntpconfig.yml     - ../tasks/interfacesettings.yml     - ../tasks/l3interface.yml     - ../tasks/snmpcreate.yml     - ../tasks/copyrunstart.yml   loop_control:     loop_var: defaultconfigtasks </code></p>"},{"location":"Ansible/Ansible%20collections/","title":"Ansible collections","text":"<p>TODO:</p> <p>README.md: What is this collection about galaxy.yml: Contains metadata about your collection docs/: local documentation for the collection playbooks/: playbooks reside here not created but typical playbooks/tasks/: this holds 'task list files' for include_tasks/import_tasks usage plugins/: all ansible plugins and modules go here, each in its own subdir (example) plugins/modules/: ansible modules (example) plugins/lookups/: lookup plugins (example) plugins/filters/: Jinja2 filter plugins plugins/... rest of plugins README.md: a description of the new functionality provided by the plugins roles/: directory for ansible roles</p>"},{"location":"Ansible/Ansible%20plugins/","title":"Ansible plugins","text":"<p>An ansible plugin is code that is write so you can use it. To me (as of right now), I dont really understand the difference between a plugin and a module.</p> <p>There are different kinds of plugins  - action - filter   - This is a jinja 2 filter - callback   - the result from the task   - use case     - mail     - slack     - teams     - loggers     - timer is the terminal windows - lookup - strategy - connection</p>"},{"location":"Ansible/Ansible%20things%20to%20learn/","title":"Ansible things to learn","text":"<p>Playbooks inventory - dynamic - static Ansible runner Ansible execution environment - execution-environment.yml</p> <pre><code>version: 3\ndependencies:\n  ansible_core:\n    package_pip: ansible-core==2.14.4\n  ansible_runner:\n    package_pip: ansible-runner\n  galaxy: requirements.yml\n  python: requirements.txt\n\nimages:\n  base_image:\n    name: quay.io/ansible/awx-ee:latest\n\n</code></pre> <ul> <li>requirements.txt</li> </ul> <pre><code>\n\n</code></pre> <ul> <li>requirements.yml modules plugins roles collections ansible builder</li> </ul> <p>Awx - webhooks</p>"},{"location":"Ansible/best%20practices/","title":"Best practices","text":"<ul> <li> <p>You should not put localhost in your playbook you should put it in the inventory file. if you put a localhost in the playbook, you lose the ability to doing forking.</p> </li> <li> <p>You should be running some sort of linter.</p> </li> <li> <p>It is best practice to only put what you in the execution environment. </p> </li> </ul>"},{"location":"Cert%20info/200-901-DevASC/Cisco%20API/","title":"Cisco API","text":""},{"location":"Cert%20info/200-901-DevASC/Cisco%20API/#what-is-an-sdk","title":"What is an SDK?","text":"<p>SDK is a software development kit that allows a user to grab pre-written APIs and communicate and an endpoint. Alternatively in the case of Python, you could create your own class that can call an API and program it the exact way you want it. or you can use an SDK and cut down on coding time and maintenance. A good SDK has these qualities - Is easy to use - Is well documented - Has vault-added functionality - Integrates will with other SDKs - Has minimal impact on hardware resources SDKs provide the following advantages - Quicker integration - Faster and more efficient development - Brand control - Increased security - Metrics</p>"},{"location":"Cert%20info/200-901-DevASC/Cisco%20API/#cisco-meraki","title":"Cisco Meraki","text":"<p>Cisco Meraki cloud platform provides several APIs - Captive Portal API - Scanning API - MV Sense Camera API - Dashboard API Cisco Meraki dashboard only allows 5 API calls per second per organization, in the first second there is a burst of additional 5 API calls that can be made. If you notice your API calls are giving back too much info your may want to take a pagination approach and limit your calls. some options for pagination in Meraki include: - perPage: The number of entries to be returned. - startingAfter: A value used to indicate that the returned data will start immediately after this value - endingBefore: A value used to indicate that the returned data will end immediately before this value. If you have large configuration changes that need to happen you can use action batches in order to send multiple configurations request in a single transaction. this will avoid hitting the API limits.  </p>"},{"location":"Cert%20info/200-901-DevASC/Cisco%20API/#cisco-compute-management-platforms-and-api","title":"Cisco Compute management platforms and API","text":"<p>Cisco UCS - Cisco UCS manager   - This is built for cisco ecosystem   - Built for Cisco server nodes - Cisco UCS Central   - manage multiple Cisco UCS Domains from a central point   - Uses UCS manager apis - Cisco Intersight   - cloud hosted management for cisco UCS and Cisco hyperFlex   - Tight integration with Cisco TAC Cisco UCS Director - This is built as a multi-platform tool</p>"},{"location":"Cert%20info/200-901-DevASC/Cisco%20API/#cisco-collaboration-platforms","title":"Cisco Collaboration Platforms","text":"<p>Cisco Unified communications manager Cisco finesse - Looks like a way to manage your virtual phone - Any you can manage a group of phones or a team of people. Cisco webex Cisco Webex is a group of products that can work together to collaborate with a team or host meetings - webex meetings - Webex teams - webex devices - webex board - any others </p>"},{"location":"Cert%20info/200-901-DevASC/Cisco%20API/#cisco-security-platforms","title":"Cisco security Platforms","text":"<p>Cisco firepower Cisco Amp and cisco threat grid Cisco umbrella Cisco ISE</p>"},{"location":"Cert%20info/200-901-DevASC/Exam%20Details/","title":"Exam Details","text":""},{"location":"Cert%20info/200-901-DevASC/Exam%20Details/#key-notes-about-the-exam","title":"Key notes about the exam","text":"<ul> <li>Test is 120 mins</li> <li>This is a very developer based test</li> </ul>"},{"location":"Cert%20info/200-901-DevASC/Exam%20Details/#items-i-know-or-have-heard-of","title":"Items I know or have heard of","text":"<p>Section 1 - Software development and design - Data formats - Parsing data - Software development methods - Advantages of common design patterns - Advantages of version control - Utilize Git</p> <p>Section 2 - Understanding and using APIs - Construct a REST API - Troubleshoot a problem given the HTTP code - Identify parts of an HTTP response - Utilize common API authentication mechanisms - Construct a Python script that calls a REST API using the request library</p> <p>Section 3 - Cisco platforms and development - Construct a Python script that uses a Cisco SDK - Construct code to perform specific operation based on a set of requirements</p> <p>Section 4 - Application deployment and security - Identify attributes of different applications deployment models - Identify the attributes of these application deployment types - Explain how firewall, DNS, load balancers, and reverse proxy in application deployment - Utilize Bash commands</p> <p>Section 5 - Infrastructure and automation - Compare controller-level to device-level management - Describe the user and roles of network simulation and test tools - Describe the principles of infrastructure as code - Describe the capabilities of automation tools</p> <p>Section 6- Network fundamentals - Describe Mac addresses and VLANs - Describe IP addresses, routes, subnet mask/prefix and gateways - Describe functions of common network components - Interpret a basic network topology diagram - Describe the functions of management, data and control planes - Describe the functionality of IP services - Recognize common protocol port values - Identify cause of application connectivity issues - Explain the impacts of network constraints on applications</p>"},{"location":"Cert%20info/200-901-DevASC/Exam%20Details/#items-i-have-no-idea","title":"Items I have no idea","text":"<p>Section 1 - Software development and design - Concepts of test-driven development - Benefits of organizing code</p> <p>Section 2 - Understanding and using APIs - Describe common usage patterns related to webhooks - Identify the constraints when consuming APIs - Explain common HTTP codes - Compare common API styles</p> <p>Section 3 - Cisco platforms and development - Describe the capabilities of Cisco management platforms - Describe the capabilities of Cisco compute management platform - Describe the capabilities of Cisco collaboration platform - Describe the capabilities of Cisco security - Describe teh device level APIs and dynamic interfaces for IOS XE and NX-OS - Identify the appropriate DevNet resource - Apply concepts of model driven programmability in a Cisco environment</p> <p>Section 4 - Application deployment and security - Describe benefits of edge computing - Describe components for a CI/CD pipeline in application deployment - Construct a Python unit test - Interpret contents of a Dockerfile - Utilize Docker images in a local developer environment - Identify application security issues related to secret protection, encryption, and data handling - Describe top OWASP threats - Identify the principles of DevOps practice</p> <p>Section 5 - Infrastructure and automation - Describe the value of model driven programmability for infrastructure automation - Describe the components and benefits of CI/CD pipeline in infrastructure automation - Identify the workflow being automated by Python script that uses Cisco APIs - Identify the workflow being automated by an Ansible playbook - Identify the workflow being automated by a Bash script - Interpret the results of a RESTCONF or NETCONF query - Interpret basic YANG model - Interpret a unified diff - Describe the principles and benefits of a code review process - Interpret sequence diagram that includes API calls</p> <p>Section 6 - Network fundamentals</p>"},{"location":"Cloud/Azure/AZ-700%20-%20Networking/Extra%20notes/","title":"Extra notes","text":"<p>aka.ms/learn - all the training notes are on the link above</p> <p>can you grab this PS command from an existing vnet? https://docs.microsoft.com/en-us/azure/virtual-network/quick-create-powershell</p>"},{"location":"Cloud/Azure/AZ-700%20-%20Networking/Mod%201%20%3A%20Introduction%20to%20Azure%20Virtual%20Network/","title":"Mod 1 : Introduction to Azure Virtual Network","text":"<p>Everything starts with a virtual network - communications with the internet - communication between azure resources</p>"},{"location":"Cloud/Azure/AZ-700%20-%20Networking/Mod%201%20%3A%20Introduction%20to%20Azure%20Virtual%20Network/#capabilities-of-azure-virtual-networks","title":"Capabilities of Azure Virtual Networks","text":"<ul> <li>Communication with the internet</li> <li>Communication between Azure resources</li> <li>There are three key mechanisms through which azure resource can communicate: VNets, VNet service endpoint and VNet peering</li> <li>Communication between on-premises resources</li> <li>Some options to connect to on-prem include: point-to-site VPN, Site-to-site VPN, Azure ExpressRoute</li> <li>Filtering network traffic</li> <li>Routing network traffic</li> <li>You can implement route tables or BGP routes to override the default routes Azure creates.</li> </ul>"},{"location":"Cloud/Azure/AZ-700%20-%20Networking/Mod%201%20%3A%20Introduction%20to%20Azure%20Virtual%20Network/#design-considerations-for-azure-vitrual-networks","title":"Design considerations for Azure Vitrual Networks","text":"<p>You can only use the RFC 1918 networks in azure. Careful that you do not overlap subnets that are on-prem or other resource groups inside of azure subscription. Azure will reserve 5 ip address from a subnet( example for a /24 network below) - x.x.x.0: network address - x.x.x.1: Reserved be Azure for the default gateway - x.x.x.2,x.x.x.3: Reserved by Azure to map the Azure DNS IPs to the VNet space - x.x.x.255: Network broadcast address</p> <p>When designing in Azure there are some of the same principles as designing an on-prem network, but there are also going to be unique features as well. Some design considerations include: - VNets - Subnets - Micro-segmentation - Determine a naming convention - Which regions or availability zones to put your resources in   - There are three categories for availability zones:     - Zonal services - Resources that are pinned to a specific Azure region     - Zone-redundant services - Resources are replicated or distributed across zones automactically.     - Non-regional services - Services are always available from Azure geographies and are resilient to zone-wide outages as well as region-wide outages.</p>"},{"location":"Cloud/Azure/AZ-700%20-%20Networking/Mod%201%20%3A%20Introduction%20to%20Azure%20Virtual%20Network/#notes","title":"NOTES:","text":"<p>BastionHost: The Azure Bastion service is a new fully platform-managed PaaS service that you provision inside your virtual network. It provides secure and seamless RDP/SSH connectivity to your VM directly in the Azure portal over SSL. When you connect via Azure Bastion, your VM does not need a public ip address.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%201%20%3A%20Describe%20Cloud%20Concepts/","title":"Mod 1 : Describe Cloud Concepts","text":"<p>what is cloud computing? The ability to rent compute and storage from someone else's data center. compute power - CPU - Ram - Backups - up to date storage - Amount of Data - Grow as you need</p> <p>Why can Cloud computing be cheaper? - Pay as you go/Only pay for what you use - Run services only as you need (shutdown at nighttime) - Grow as you need and reduce as you need</p> <p>Why might I move to the cloud? - teams deliver new features to their users at record speeds - Users expect an increasing rich and immersive experience with their devices and their software</p> <p>What is Azure? Here are just some of the services/offerings by azure - IaaS - PaaS - SaaS - Pay-as-you-go - Cloud-based storage - Azure app services - Azure Functions - Azure containers - Azure kubernetes  - Databases - azure cosmos DC - AI and Machine learnings - Regional data centers - Azure portals</p> <p>High level - How does Azure work? - Virtualization     - hypervisor each data center has many servers each server includes hypervisor Network switch provides connections to all the servers 1 server in each rack runs a piece of software called the \"Fabric controller\" Each \"Fabric controller\" is connected to a piece of software called the \"orchestrator\" The \"orchestrator\" is responsible for everything that happens in Azure, including responding to users Users make request to the \"orchestrator\" via the web api the Web api can be called by many tools, including the web interface of the azure portal When a user wants a VM, the request is sent to the orchestrator, the orchestrator picks the best server rack, the fabric controller creates the VM</p> <p>Azure services broken down by Main catagories - Compute   - VM   - ECT - Networking   - Allows you to connect on Prem   - VPN   - Load balancing - Storage   - File    - disk   - blob   - Archival - Mobile   - management   - app control? - Databases   - proprietary   - open source - Web - Internet of things - Big data - AI - DevOps   - CI/CD</p> <p>Different types of cloud   - Public     - No Capital expenditures to scale up.     - Applications can be quickly provisioned and deprovisioned.     - Organizations pay only for what they use.   - Private     - Hardware must be purchased for start-up and maintenance.     - Organizations have complete control over resources and security.     - Organizations are responsible for hardware maintenance and updates.   - Hybrid     - Provides the most flexibility.     - Organizations determine where to run their applications.     - Organizations control security, compliance, or legal requirements.</p> <p>What are some cloud computing advantages? - High availability - Scalability   - Vertically - increase compute capacity by adding RAM or CPU.   - Horizontally - adding VMs. - Elasticity - Global reach - Agility - Geo-distribution - Disaster recovery - Fault Tolerance - Customer latency capabilities - Predictive cost considerations - Security</p> <p>Capital expenses vs operating expenses - Capital expenditures (CapEx)   - This is more project based   - or this is where you are given the cash up front or the availability of the cash. - Operational expenditures (OpEx)   - this is the concept of you are bill for a service and you pay that service once you are billed.   - Employees are more operational expense, where contractors are more capital expense.   - This is where cloud computing fits in.</p> <p>Cloud service modules - IaaS - PaaS - SaaS - Serverless computing Here is a good break down of the services </p> <p>What is Serverless computing - With serverless computing applications, the cloud service provider automatically provisions, scales and manges the infrastructure required to run the code.   - Azure functions is code running your service and not the underlying platform or infrastructure. It creates infrastructure based on an event.   - Azure logic apps is a cloud service that helps you automate and orchestrate tasks, business processes and workflows when you need to integrate apps, data systems, and services.</p> <p>Azure organization structure - Management groups   - These groups help you mange access, policy, and compliance for multiple subscriptions - Subscription   - Groups together user accounts and the resources that have been created by those users.   - used to manage cost and access to resource group and resources - Resource group   - Resources are combinded into resource groups, which act like a logical container into which azure resources like web apps, databases and storage accounts are deployed and managed. - Resources   - instances of services that you create, like virtual machines, storage, or sql databases.   Here is a good breakdown of the organization structure.</p> <p></p>"},{"location":"Cloud/Azure/AZ-900/Mod%202%20%3A%20Core%20Azure%20Services/","title":"Mod 2 : Core Azure Services","text":"<p>What are Azure Architectural Components</p> <p> - Regions and availability zones   - Regions     - Regions are made up of one or more data centers in close proximity.       - Regions are made up of multiple Availability zones     - Provides flexibility and scale to reduce customer latency.     - Preserve data residency with a comprehensive compliance offering.   - Region pairs     - At least 300 miles of separation between region pairs.     - Automatic replication for some services.     - Prioritized region recovery in the event of outage.     - Update are rolled out sequentially to minimize downtime.     - For DR reasons you would want to your Region pairs ready to go when ever you need them.   - Availability zones     - Availability Set       - Availability Set Is a set of racks     - Availability zones       - Availability zones is a Data center       - Provides protection against downtime due to data center failure.       - Physically separates data center within the same region.       - Each data center is equipped with independent power, cooling, and networking.       - Connected through private fiber-optic networks.</p> <p></p> <ul> <li>Subscriptions and resource groups</li> </ul> <p>What are the core azure resources - Compute   - Azure compute is an on-demand computing service that provides computing resources such as disks, processors, memory, networking, and operating systems.   - Examples     - VM       - Software emulations of a physical computer.       -  Includes virtual processor, memory, storage, and networking.       - IaaS offering that provides total control and customization.     - App services       - Azure app services is a fully managed platform to build, deploy, and scale web apps and APIs quickly       - Works with .net, .net core, node.js, java, python or php       - PaaS offering the enterprise-grade performance, security, and compliance requirements.      - Container instances       - Azure container services         - Azure containers are light-weight, virtualized environment that does not require operating system management, and can respond to changes on demand.           - Azure container instances             - A PaaS offering that runs a container in Azure without the need to manage a VM or additional services.           - Azure kubernetes services             - An orchestration service for containers with distributed architectures and large volumes of containers.     - Windows virtual desktop        - Windows virtual desktop is a desktop and app virtualization that runs in the cloud.         - Crete a full desktop virtualization environment without having to run additional gateway servers.         - Publish unlimited host pools to accommodate diverse workloads.         - Reduce cost with pooled, multi-session resources. - Networking   - Azure virtual network     - Enables Azure resources to communicate with each other, the internet, and on-premises network.   - VPN gateway     - Used to send encrypted traffic between an Azure virtual network and an on-premises location over the public internet.   - Azure express route     - Extends on-premises networks into Azure over a private connection that is facilitated by a connectivity provider. - Storage   - GRS VS LRS     - LRS means the data will only be housed in its own data center and will only be backed up in that data center     - GRS means the data will be replicated in a different data center. adding a layer of protection for your data    - types of storage     - Container storage (blob)       - Optimized for storing massive amounts of unstructured data, such as text or binary data.     - Disk storage       - Provides disks for VM, applications, and other services to access and use.     - Azure files       - Sets up highly available network file shares that can be access by using the standard SMB protocol.   - Ways to access storage ( you can switch between these are any time)     - Hot ( most expensive)       - Optimized for storing data that is accessed frequently.     - Cool       - Optimized for storing data the is infrequently accessed and stored for at least 30 days.     - Archive (cheaper)       - Optimized for storing data that is rarely accessed and stored for at least 180 days with flexible latency requirements. - Databases   - Azure Cosmos database     - A globally distributed database service that elastically and independently scales throughput and storage.   - Azure SQL database     - A relational database as a service (DaaS) based on the latest stable version of microsoft SQL server database engine   - Azure database for MySQL     - A fully-managed MySQL database service for app developers   - Azure database for PostgreSQL     - A relational database service based on the open-source Postgres database engine.</p> <p>What are the Azure resources? - Azure resources are components like storage, virtual machines, and networks that are available to build cloud solutions. - EVERYTHING IS A RESOURCE: storage, IP Address, VM. EVERYTHING. - The main Azure resources are:   - Virtual machines   - Storage accounts   - Virtual networks   - App services   - SQL databases   - Functions</p> <p>Key notes about SLA for a VM - Single VM - 99.9% - Availability Set - 99.95% - Availability Zone - 99.99%</p> <p>Resource group - A resource group is a container to manage and aggregate resources in a single unit.   - Resource can exist in only one resource group.   - Resources can exist in different regions.   - Resources can be moved to different resource groups.   - Applications can utilize resource groups.</p> <p>Azure resource manager - The Azure resource manager (ARM) provides a management layer that enables you to create, update, and delete resource in your Azure subscription. </p> <p></p> <p>Azure Subscriptions - An Azure subscription provides you with authenticated and authorized access to Azure accounts.   - Billing boundary     - Generates separate billing reports and invoices for each subscription.   - Access control boundary     - Manage and control access to resources that users can provision with specific subscriptions.</p> <p>Management Groups - Management groups can include multiple Azure subscriptions. - Subscriptions inherit conditions applied to the management group. - 10,000 management groups can be supported in a single directory. - A management group tree can support up to six levels of depth.</p> <p></p> <p>What is the Azure Marketplace? Azure marketplace helps connect users with Microsoft partners, independent software vendors ans startups that are offering their solution ans services, which are optimized to run on Azure. </p>"},{"location":"Cloud/Azure/AZ-900/Mod%203%20%3A%20Core%20Solutions/","title":"Mod 3 : Core Solutions","text":"<p>Azure IoT - Internet of things (IoT) is the ability for devices to garner and then relay information for data analysis. - Azure IoT central   - A fully managed global IoT SaaS solution that makes it easy to connect, monitor, and manage IoT assets at scale. - Azure IoT hub  - A managed service hosted in the cloud that acts as a central message hub for bi-directional communication between IoT applications and the devices it manages - Azure Sphere   - A secured, high-level application platform with built-in communication and security features for internet-connected devices.</p> <p>Big Data and analytics - Azure synapses analytics   - A cloud-based enterprise data warehouse - Azure HDInsight   - A fully-managed, open-source analytics service for enterprise - Azure Databricks   - Apache spark based analytics service</p> <p>Artificial intelligence and Machine learning - Azure machine learning   - Cloud-based to develop, train, and deploy machine learning models. - Cognitive services   - Quickly enable apps to see, hear, speak, understand, and interpret user's needs. - Azure bot services   - Develop intelligent, enterprise-grade bots.</p> <p>Serverless computing - Azure functions   - Event based code running your service and not the underlying infrastructure.   - This is a way of decoupling functions in your code and storing your functions outside your app.   - This is language agnostic. Meaning that you can write a function in Ruby and a script in python. - Azure logic apps   - Automate and orchestrate tasks, business processes and workflows to integrate apps.   - Same idea as the function side, just with logic. AKA if/else if/else statements.</p> <p>Develop your apps with DevOps and Github - Azure DevOps   - Development collaboration tool including pipelines, Kanban boards, and automated cloud-based load testing. - GitHub   - Software development hosting with version control, source code management, and bug/task management. - GitHub actions for Azure   - Automate software workflow to build, test, and deploy from within GitHub - Azure DevTest Labs    - Quickly create environments in Azure while minimizing ware and controlling cost.</p> <p>Management tools available in Azure - ARM - Azure portal - Azure powershell - Azure mobile app - CLI - Azure REST API - Azure cloud shell</p> <p>Azure Advisor - Azure Advisor analyzes deployed Azure resources and makes recommendations based on the best practices to optimize Azure deployments   - Reliability   - Security   - Performance   - Cost   - Operational excellence</p> <p>Azure Monitor - Azure monitor maximizes the availability and performance of the applications and services by collecting analyzing and acting on telemetry from cloud and on-premises environments.   - Applications insights   - Log analytics   - Smart alerts   - Automation actions   - Customized dashboards</p> <p>Azure service health - Evaluate the impact of Azure service issues with personalized guidance and support, notifications, and issues resolution updates.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/","title":"Mod 4 : Azure Security","text":""},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#azure-security-center","title":"Azure Security Center","text":"<p>Azure security center is a monitoring service that provides threat protection across both Azure and on-prem data centers. - Provides security recommendations. - Detect and block malware. - Analyze and identify potential attacks. - Just in time access control for ports. Capabilities - Policy Compliance   - Run policies across management groups, subscriptions or tenants. - Continuous Assessments   - Assess new and deployed resources to ensure that they are configured properly. - Tailored recommendations   - Recommendations based on existing workloads with instructions on how to implement them. - Threat protection   - Analyze attempted threats through alerts and impacted resource reports.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#azure-sentinel","title":"Azure Sentinel","text":"<p>Azure sentinel is a security information management (SEIM) and security automated response (SOAR) solution that provides security and threat intelligence across an enterprise.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#azure-dedicated-hosts","title":"Azure dedicated hosts","text":"<p>Azure dedicated hosts provides physical servers that host one or more Azure virtual machine that is dedicated to a single organization's workload. Benefits - Hardware isolation at the server level. - Control over maintenance event timings. - Aligned with Azure hybrid use benefits.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#defense-in-depth","title":"Defense in depth","text":"<ul> <li>Layered approach to securing computer systems.</li> <li>provides multiple levels of protection.</li> </ul>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#network-security-groups-nsgs","title":"Network Security Groups (NSGs)","text":"<p>NSGs filter network traffic to and from azure resources on Azure virtual networks - Set inbound and outbound rules to filter by source and destination IP address, port. and protocols. - Add multiple rules, as needed, within subscription limits. - Azure applies default, baseline security rules to new NSGs. - Override default rules with new, higher priority rules.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#azure-firewall","title":"Azure Firewall","text":"<p>A stateful, managed Firewall as a Service (FaaS) that grants/denies server access based on originating IP address, in order to protect network resources. - Applies inboud and outbound traffic filtering rules. - Built-in high availability - Unrestricted cloud scalability. - Uses Azure monitor logging. - Azure also has WAF.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%204%20%3A%20Azure%20Security/#azure-ddos-protection","title":"Azure DDoS protection","text":"<p>You can also enable DDoS. It is turned on by default.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/","title":"Mod 5 : Identitiy, governance, privacy, and compliance","text":""},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#what-is-azure-ad","title":"What is Azure AD?","text":"<ul> <li>Microsoft Azure's cloud-based identity and access management service.</li> </ul>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#what-can-azure-ad-do","title":"What can Azure AD do?","text":"<ul> <li>Authentication</li> <li>SSO</li> <li>Application management</li> <li>Business to business</li> <li>Business to Customer identity services</li> <li>Device management</li> </ul>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#conditional-access","title":"Conditional Access","text":"<p>Conditional access is used to AAD to bring signals together, to make decisions, and enforce organizational polices. - User or group membership - Ip address - Device - Application - Risk Detection</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#resource-locks","title":"Resource locks","text":"<ul> <li>Protect your Azure resource from accidental deletion or modification</li> <li>Manage locks at subscription, resource group, or individual resource levels within Azure portal</li> </ul>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#azure-policy","title":"Azure Policy","text":"<p>Azure policy helps to enforce organizational standards and to assess compliance at-scale. Provides governance and resource consistency with regulatory compliance, security, cost and management.  - Evaluates and identifies Azure resources that do not comply with your policies. - Provides built-in policy and initiative definitions, under categories such as storage, networking, compute, security center, and monitoring.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#azure-blueprints","title":"Azure Blueprints","text":"<p>Azure blueprints makes it possible for development teams to rapidly build and stand up new environments. Development teams can quickly build trust through organizational compliance with a set of built-in components (such as networking) in order to speed up development and delivery. - Role assignments - Policy assignments - Azure resource manager templates - Resource groups</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#compliance","title":"compliance","text":"<p>Some compliance offerings - CJIS - HIPAA - CSA Star Certification - ISO/IEC 27018 - EU Model Clauses - NIST</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#microsoft-privacy-statement","title":"Microsoft Privacy Statement","text":"<p>The Microsoft privacy statement explains - What data Microsoft processes - How Microsoft processes it - What purpose the data is being used for</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#trust-center","title":"Trust center","text":"<p>Learn about security, privacy, compliance, policies, features and practices across microsoft't cloud products.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%205%20%3A%20Identitiy%2C%20governance%2C%20privacy%2C%20and%20compliance/#azure-compliance-documentation","title":"Azure compliance documentation","text":"<p>Microsoft offers a comprehensive set of compliance offering to help your organization comply with national, regional, and industry-specific requirements that govern the collections and use of data.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%206%20%3A%20Azure%20pricing%20and%20lifecycle/","title":"Mod 6 : Azure pricing and lifecycle","text":""},{"location":"Cloud/Azure/AZ-900/Mod%206%20%3A%20Azure%20pricing%20and%20lifecycle/#the-factors-that-can-affect-cost","title":"The factors that can affect cost","text":"<p>The factors include: 1. Resource type 2. Services    - Azure usage rates and billing periods can differ between Enterprise, Web Direct, and CSP customers. 3. Location 4. Bandwidth    - Some inbound data transfers are free.  5. Reserved Instances    - You can commit to buying one-year or three-year plans for multiple products. Reservations can reduce cost up to 72% when compared to pay-as-you go. 6. Azure Hybrid use benefit </p>"},{"location":"Cloud/Azure/AZ-900/Mod%206%20%3A%20Azure%20pricing%20and%20lifecycle/#pricing-calculator","title":"Pricing calculator","text":"<p>The pricing calculator is a tool that helps you estimate teh cost of azure products. the options that you can configure the pricing calculator vary between products, but basic configuration options include: - Region - Tier - Billing options - Support options - Programs and offers - Azure dev/test pricing Total cost of ownership calculator - A tool to estimate cost savings you can realize by migrating to Azure. - A report compares the costs of on-premises infrastructures with the costs of using Azure products and services in the cloud.</p>"},{"location":"Cloud/Azure/AZ-900/Mod%206%20%3A%20Azure%20pricing%20and%20lifecycle/#azure-cost-management","title":"Azure cost management","text":"<ul> <li>Reporting - billing reports</li> <li>Data enrichment</li> <li>Budgets - Set spend budget</li> <li>Alerting - when cost exceed limits</li> <li>Recommendation - cost recommendations</li> </ul>"},{"location":"Cloud/Azure/AZ-900/Mod%206%20%3A%20Azure%20pricing%20and%20lifecycle/#sla-and-lifecycles","title":"SLA and lifecycles","text":"<p>SLAs describes Microsoft's commitments for uptime and connectivity - SLAs are based on individual products and services - Detailed agreements on the service provided, and any exceptions to the SLA - Free and preview features/services do not offer SLAs Actions that affect your SLA - Lower your SLA    - Adding more services   - Choosing free or non-SLA services - Raise your SLA    - Availability zones   - Redundant systems Azure preview program     With Azure previews, users can test beta and other pre-release features, products, services software and regions to provide feedback. - Public preview: all Azure customers can evaluate the new features - Generally available (GA): after public preview is completed, all customers can use feature, and region availability will vary.  Monitoring services and feature updates - Azure updates provides info about the Azure product, services and features, in addition to product roadmaps and availability. - view details about all azure updates and their status. - Browse and search for updates. - Subscribe to azure updates notifications by RSS.</p>"},{"location":"Cloud/Azure/Lab/Notes%20about%20labing%20in%20azure/","title":"Notes about labing in azure","text":"<p>setting up a home lab - input a payment method   - need a Credit card      - access this under billing profile &gt; payment methods     - cost management + billing | billing account | billing profile | payment methods - create a new subscription - create a resouce group   - decide where you want your resource group to reside - create a vnet   - I will start by creating a very basic one with no NSG or bastionhost, ect   - assign a network to the vnet - create a subnet   - you can assign this subnet to the vnet   - you can only create a subnet inside a vnet ( as far as i know)   - peering to hub   - I have created 3 vnets</p> <p>Terraform - install terraform - install azure cli on host   - https://docs.microsoft.com/en-us/cli/azure/install-azure-cli-linux?pivots=apt   -  - login to azure on vm   - \u279c  terraform training git:(main) \u2717 az login     A web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is    available or if the web browser fails to open, use device code flow with <code>az login --use-device-code</code>.     ^C%                                                                                                                                                                                           \u279c  terraform training git:(main) \u2717 az login --use-device-code      To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code RNM7DFMNH to authenticate.</p> <pre><code>Things i need to look up\n- what is a gateway subnet?\n  - really only used if you want to connect on prem\n  - vpn gateway or express route\n- securing devices to the internet\n</code></pre>"},{"location":"Developer%20Training/API/","title":"Application Programming Interfaces (API)","text":"<ul> <li>Northbound APIs</li> <li>Often a network controller to its management software.</li> <li>Best practices suggest that the traffic should be encrypted using TLS between software and the controller.</li> <li>Southbound APIs</li> <li>This would be pushing the configuration to the device from the controller. </li> </ul> <p>As network engineers we have been using this model of north and southbound aps for years and years. Think of wireless access points and the wireless controller.</p>"},{"location":"Developer%20Training/API/#synchronous-vs-asynchronous-apis","title":"Synchronous vs Asynchronous APIs","text":"<p>Synchronous APIs means that your application is waiting for a response from the API in order to continue the process. You send a command, wait for a response, then send the next command. This works very much like TCP. Synchronous also means slower response times. You man need this type of API communication if you need data from another API before your program can continue. good example would be creating tokens. Asynchronous is just the opposite. You send a command, then you send another and another. You never need to wait to find out if the first command was successful. </p>"},{"location":"Developer%20Training/API/#representational-state-transfer-rest-apis","title":"Representational State Transfer (REST) APIs","text":"<ul> <li>REST APIs are often referred to as RESTful API</li> <li>RESTful APIs use HTTP methods to gather and manipulate data.</li> </ul> CRUD Function Action CREATE Inserts data inside a database or an application READ Retrieves data from a database or an application UPDATE Modifies replaces data in a database or an application Delete Removes data from a database or an application"},{"location":"Developer%20Training/API/#restful-api-fundamentals","title":"RESTful API Fundamentals","text":""},{"location":"Developer%20Training/API/#api-types","title":"API Types","text":"<ul> <li>Service API</li> <li>An application can call on another application to solve a particular problem.</li> <li>These different applications can work with out interaction from the other app, but this will extend the service for the two apps.</li> <li>Information API</li> <li>An application can call on another application to provide information.</li> <li>Hardware API</li> <li>An application can call the hardwares API to access the hardware level.</li> </ul>"},{"location":"Developer%20Training/API/#api-access-types","title":"API Access Types","text":"<ul> <li>Private</li> <li>For internal use only. Used inside a company only.</li> <li>Partner</li> <li>APIs that are shared to specific business partners.</li> <li>Public</li> <li>API that can be accessed by all.</li> </ul>"},{"location":"Developer%20Training/API/#restful-api-authentication","title":"RESTful API Authentication","text":"<ul> <li>Basic</li> <li>One of the simplest and most common authentication methods used in APIs.</li> <li>IMPORTANT NOTE Basic Auth is sent not encrypted in your program or to the southbound device. You often will use SSL or TLS to encrypt your HTTP call to prevent man in the middle attacks.</li> <li>Another issue is that the encoded string is sent back and forth in your APIs calls.</li> <li>API Keys</li> <li>An API key is a predetermined string that is passed from the client to the server. It is intended to be a pre-shared secret and should not be well known or easy to guess.</li> <li>API keys can be passed to the server in three different ways:<ul> <li>String</li> <li>Request header</li> <li>Cookie</li> </ul> </li> <li>The string is passed with every call you make.</li> <li>If you are making multiple calls you would want to look into using a cookie or request header.</li> <li>Custom Tokens</li> <li>Tokens are a way of authenticating using the REST API. You authenticate once and you receive your token, you use the token to authenticate. </li> </ul>"},{"location":"Developer%20Training/API/#http","title":"HTTP","text":""},{"location":"Developer%20Training/API/#http-basics","title":"HTTP Basics","text":"<p>In order for a HTTP request to be successful, the client need to include four items - URL (uniform resource locator)    - The URL is the location where the service resides on the internet/intranet   - A URL typically has four components     - Protocol       - HTTP     - Server/Host address       - first part of the URL the DNS name or ip address     - Resource       - Location on the server where the data is stored     - Parameters       - a filter or to clarify request - Method   - Different kinds of request methods includes  </p> Method Details CRUD GET Retrieve data from the server Read HEAD Request for header information from a get request POST Post data or add new data server Create PUT Request to ask server to store or update data Update PATCH Request server to partially store or update data Update DELETE Request server to delete information Delete TRACE Request to ask server to return a diagnostic trace OPTIONS Ask the server for a list of request methods CONNECT Ask a proxy to make a request to another server <ul> <li>List of headers</li> <li>The headers contain the meta data about tn HTTP request. <ul> <li>The host name, connection type, The type of data you want to receive, the language, ect</li> </ul> </li> <li>Body</li> </ul>"},{"location":"Developer%20Training/API/#http-functions-calls","title":"HTTP functions calls","text":"HTTP Function Action GET Request data from a destination POST Submits data to a specific destination PUT Replaces data at a specific destination Patch Appends data to a specific destination Delete Removes data from a specific destination"},{"location":"Developer%20Training/API/#response-codes","title":"Response codes","text":"<p>The types of response codes you will see - 1xx (informational) - The request has been successfully received. The server is continuing the process - 2xx (success) - The request was successful and is completed. - 3xx (redirection) - Further action must be taken to complete this request. - 4xx (client error) - The request cannot be understood or is unauthorized. - 5xx (server error) - The server failed to fulfill a request.</p> <p>Common response codes | Status Code | Meaning | |-|-| | 100 | Continue | | 200 | Okay |  | 301 | Move permanently | | 302 | Found and redirect | | 304 | Not modified |  | 400 | Bad request | | 401 | Authentication required | | 403 | Forbidden |  | 404 | Not found |  | 405 | Method not allowed | | 408 | Request timed out |  | 414 | request URI too large | | 429 | Too many requests HTTP response headers |  | 500 | Internal server error | | 501 | Method not implemented | | 502 | Bad gateway |  | 503 | Service unavailable | | 504 | Gateway timeout | </p>"},{"location":"Developer%20Training/API/#http-headers","title":"HTTP Headers","text":"<p>There are four distinct types of headers - General Headers   - Headers from this category are not specific to any particular kind of message.   - They are primarily used to communicate information about the message itself and how to process it. - Request Headers   - These headers carry information about the resource to be fetched.   - They also contain the information about the client.   - Examples     - Accept-Charset     - Accept-Datetime     - Accept-Encoding     - Accept-Language - Response Headers   - These headers hold additional information about the response and the server providing it. - Entity Headers   - These headers contain information about the response body.</p>"},{"location":"Developer%20Training/API/#https-authentication-types","title":"HTTPS authentication types","text":"<ul> <li>Anonymous (no authentication)</li> <li>Basic (Base64-encoded)</li> <li>Bearer (HTTP implementation of custom token authentication)</li> <li>Digest (MD5-hashed credentials)</li> <li>Mutual (two-way authentication)</li> <li>Other uncommon schemes</li> </ul>"},{"location":"Developer%20Training/API/#webhooks","title":"Webhooks","text":"<p>Webhooks are user-defined HTTP callbacks. Also called reverse APIs. When you want an event to happen based on a trigger that occurs. ngrok is a free tool that you can use to test out your webhooks.</p>"},{"location":"Developer%20Training/API/#rest-constraints","title":"REST Constraints","text":"<p>REST defines six architectural constraints that make any web service a truly RESTful API. These are the REST constraints: - Client/server   - A client must know the URIs on the server   - The interaction is where the client initiates requests to the server and the server sends back responses. - Stateless   - REST services must be stateless.   - Each individual request contains all the information that the server needs to preform the request   - The URI identifies the resource, and the body contains the stat of the resource.   - A stateless service is easy to scale horizontally, allowing for additional service to be added or removed as necessary. - Cache   - Response data must be implicitly or explicitly labeled as cacheable or non-cachable.    - Cashing helps to improve the performance of the client side, and helps with scalability of the server. - Uniform interface   - Identification of resources     - These identifiers are stable and do not change across interactions.   - Manipulation of resources through representations   - Self-descriptive messages   - Hypermedia as the engine of application state - layered system   - This is the idea that there can be more systems involved than just the client and server.   - some examples include proxies, load balancers, and so on. - code on demand   - This is optional.   - Sometimes the response can hand back a bit a code that the client can execute.</p>"},{"location":"Developer%20Training/API/#rest-api-versioning","title":"REST API Versioning","text":"<p>There are a few different ways to approach API versioning. Versioning is important because if allows the devs to make changes and update APIs without impacting a customers workflow. Different techniques include - URI path versioning - Query parameter versioning - Custom headers - Content negotiation   - This way allows you to version a single resource rather then the whole API.</p>"},{"location":"Developer%20Training/API/#pagination","title":"Pagination","text":"<p>What is pagination? - instead of all one api call to return all the data in one page, you need to break up that data for a better user experience.  - There are two popular approaches to pagination   - offset-based pagination     - when you set a offset number you are saying which device number you wan to start at.     - when you set a limit level you say the number of devices you want to receive back.     - example       - you have a list of 200 devices. you set an offset of 75 and a limit of 25       - with out the offset and limit, you would get all 200 devices back. with the offset and limit you would get devices 75 - 100 back   - keyset-based pagination</p>"},{"location":"Developer%20Training/API/#rate-limiting-and-monetization","title":"Rate limiting and monetization","text":"<p>Why do you need rate limiting? -  This need to happen to help with security, business impact and efficiency of the application.    -  Security    -  Business impact    -  Efficiency Some tips for rate limiting on the client side. - Avoid constant polling by using webhook to trigger updates. - Cache your own data when you need to store specialized values or rapidly review very large data sets. - Query with special filters to avoid re-polling unmodified data. - Download data during off-peak hours.</p> <p>API calls can be throttled with: - HTTP headers: headers like X-RateLimit-Limit and X-RateLimit-Remaining are used to keep track of the numbers of used and remaining API calls for a period of time. - Message queues: Incoming API calls can be put into a queue, which makes sure the API endpoint itself is not overloaded. - Software libraries and algorithms: Many libraraies and algorithms have been created for teh purpose of rate limiting, such as leaky bucket, fixed windows, and sliding log. - Reverse proxies and load balancers: LB and RPs (like NGINX) features rate limiting as a built-in feature.</p>"},{"location":"Developer%20Training/API/#simple-object-access-protocol-soap","title":"Simple Object Access Protocol (SOAP)","text":"<ul> <li>SOAP is used to access web services.</li> <li>Features can be added without major updates to the implementation.</li> <li>SOAP can use SMTP, TCP or HTTP as a transport protocol. SOAP is used to to exchange data between applications that were build on different programming languages.</li> <li>Using HTTP means that you wont need to open extra firewall ports.</li> <li>SOAP is based on XML.</li> <li>SOAP messages typically consist of four main components</li> <li>Envelope<ul> <li>The envelope encloses the XML data and identifies it as a SOAP message.</li> </ul> </li> <li>Header (optional)</li> <li>Body</li> <li>Fault (optional)<ul> <li>SOAP Fault Options</li> <li>faultCode : Not optional - Specifies the fault code of an error. Below are the fault codes.<ul> <li>VersionMismatch</li> <li>MustUnderstand</li> <li>DataEncodingUnknown</li> <li>Sender</li> <li>Receiver</li> </ul> </li> <li>faultString : Not optional - Describes an error</li> <li>faultActor : Optional - Specifies who caused a fault</li> <li>detail : Optional - Applies specific error messages</li> </ul> </li> </ul>"},{"location":"Developer%20Training/API/#remote-procedure-calls-rpcs","title":"Remote-Procedure Calls (RPCs)","text":"<p>RPC is used to execute code or a program on a remote node in a network. The client sends a call to the server, and then waits for the server to return a reply message. once the reply message is received, the results of the procedures are extracted and teh client execution is resumed. There is no limitation on concurrency, so RPC calls can also be executed asynchronously. Some notes to remember: - Error handling should be handled on the remote server. - Global variables and side effects are sometimes unknown or hidden to the client. - You will see a performance hit of the remote procedures compared to the local procedures. - Authentication should be used, because you may be unsure of the transport security. Some different types of RPC are: - JSON-RPC - XML-RPC</p>"},{"location":"Developer%20Training/API/#random-notes","title":"Random notes","text":"<p>One important bit of info to keep in mind, when using API testing them in code is very important. you don't want to troubleshoot code you created for a long time. testing you API calls will be very important troubleshooting step. SOAP vs RESTApi - SOAP request you have to send a lot of data just for a simple get like message. The body in SOAP is large. - SOAP can only use XML - SOAP is chatty, and will send you a lot of data back. - SOAP does not have a standardized interaction model. - All queries are sent with POST queries.  - REST uses HTTP methods natively (GET, POST, PUT, PATCH and DELETE) - REST has easier to manage security for the API calls - REST can use data streaming, will can make your program more efficient.  NEVER put sensitive data in the query string. only ever put this data in the headers for an RESTApi calls.</p>"},{"location":"Developer%20Training/Application%20Security/","title":"Application Security","text":"<p>Different data types - Transit - Rest</p> <p>Some Key terms to understand for security: - Asset: An asset is something you're trying to protect. - Threat: Anything you are trying to project against is known aas a threat.  - Vulnerability: A vulnerability is a weakness or gap in protection efforts. - Risk: Risk is the intersection of assets, threats, and vulnerabilities</p> <p>Common threats to applications and some mitigation options</p> Threat Mitigation options Buffer overflow Separate executable memory from non-executable memory, Randomize address spaces for data, use the built-in projection options in new software OSs and languages. Man-in-the-middle Adopt a SSL/TLS strategy for both web and Email, avoid sensitive data in public Wi-Fi or computers DoS attack Use designed protection services. Cross-site scripting Validate and sanitize input data, Employ cookie security such as timeouts encoding the client ip address and so on. Phishing Educate users to avoid falling for the bait, Detect and mark emails and sites as spam. Malware deploy technologies that continually monitor and detect malware that has evaded perimeter defenses SQL injection Use character escaping, use stored procedures as opposed to queries enforce privileges Brute force Lock the system after a specified number of attempts, use two-factor authorization. <p>OWASP list of top 10 security risks: 1. Injection 2. Broken authentication 3. Sensitive data exposure 4. XML external entities 5. Broken access control 6. Security misconfiguration 7. Cross-site scripting 8. Insecure deserialization 9. Using components with known vulnerabilities 10. Insufficient logging and monitoring</p> <p>To minimize risks, the following are some of the best practices in the industry: - Keep software up-to-date - Install end-user or device security - Use strong passwords - Implement multifactor authentication (MFA) - Install a firewall - Encrypt data</p> <p>Data security types |Data type|How to protect the data| |-|-| | Data in motion | Https, Firewalls | | Data at rest | Full disk encryption, File system encryption, Database encryption | | Data in use | Full memory encryption, CPU-based key storage, Enclaves, which are guarded and secure memory segments | </p>"},{"location":"Developer%20Training/CICD%20Pipeline-2/","title":"CICD Pipeline 2","text":"<p>What is CICD for network automation? The goal to to bring software development principles into the net devops mind frame.</p> <p>What is continuous deployment vs continuous delivery? - Delivery means to deploy all of your code changes to a testing and/or production environment after the build stage. You can schedule the config upgrade when ever. - Deployment mean that there is no human intervention. when the pipeline is passed the config change is pushed out immediately. No more release day.</p> <p>How is this done in practice? network as code network stored as source control changes are proposed in code  \"branches\" CICD builds test environment, tests code on test environment, then if successful the configuration change will be pushed out to end devices</p> <p>Tools you will need to preform this ( this is just a list i have come up with, this does not mean you need to follow the tools i have called out) - Ansible - CML - Github(Maybe, might try something else), gogs  - Drone or Jenkins - Vagrant is an option as well   - My understanding is that this will start up a local copy of cisco IOS and you can test out your configuration and verify the change worked how you thought it would.</p> <p>steps - create a branch - update network to code code - stage and commit your  - push your commits to the source control - pushing your commit to the dev branch, Your pipeline push a message to jenkins - Jenkins is a tool will run the CICD process   - You can start up a test network   - push out configuration changes to the test network   - Verify your change worked     - This one can be tedious and difficult to do     - You may have a lot of different tests that you want to run - Destroy your test network - if all tests pass, your CICD tool will merge the changes to your production environment - Depending on your choice of Continues deployment or delivery. this config change will get pushed out right away or on a schedule. - Once the change is pushed out, you will have your change </p> <p>Some notes on pipelines - Pipeline files are done in yaml - Not 100% sure on the next part but this is what i saw in the video i watched - Yaml file contains   - notify     - you may use slack, discord, teams, webex, ECT   - integration   - delivery   - deployment - CICD is not magic. you write out exactly what you want done and the CICD tool will do it - </p> <p>Many steps will be involved for this to happen. (here are some of the steps, need to think about it a bit more before. the steps right now will not be in order) - need a environment as a \"coded network\" - need to have copies of your network </p> <p>You need to first create your perfect test environment. AKA create a digital twin, then copy that XML data you receive and that will be a template that your workflow tool will use to build out the CML topology. (This will be a very tedious process at first but worth it in the end.)</p>"},{"location":"Developer%20Training/CICD%20Pipeline-2/#github-actions","title":"Github actions","text":"<p>What is github actions? - Plateform to automate developer workflows. CI/CD pipeline is a tool of the actions</p> <p>Events - This is the trigger to start a workflow Jobs - Jobs consite of steps and actions Runners - This is a container enviroment that will run our code  - Default github will run this for you, but you have the option to host your own if you would like Steps - Steps are a list of actions that must be done actions</p> <p>for github the naming convention needs to be  repo name/.github/workflows/filename.yml</p> <p>when user updates sharepoint list, event is triggered.  power automate creates a either an issue or a PR that will update a Json file (might not be json, but it could be) I will also want a check to be done to see if user updated file correctly I need a PR to be created and I need someone to manually approve it inside of github. once approval and merge is complete.  CD will take into action and will go to service now to update the fields for the device type. testing will need to happen to to check see if device type is in snow, or dnac.</p> <p>Use the following for ${{variable.name}}</p> <p>name: Python app deployment          # Name of deployment, user generated.</p> <p>on:                                  # Event   pull_request:                      # Trigger     branches: [main]</p> <p>jobs:                                # Jobs will run in parallel, but default   build:                             # User defined feild, can be anything     runs-on: ubuntu-latest           # Runner     env:       environmental_variable_name: 'environmental variable data'</p> <p>#needs: Name of a different job   # Use needs if you need one job to be dependent on a different job</p> <pre><code>steps:\n- name: Check out branch\n  uses: action/checkout@v2  # This will check out the code. Actions keyword it like a directory and checkout is a keyword that is tied to something in the actions directory\n\n- name: Run command on runner server\n  run: chmod +x foldername\n\n- name: Run python script on assigned runner\n  run: ./python_script_name.py\n</code></pre>"},{"location":"Developer%20Training/CICD%20Pipeline/","title":"CICD Pipeline","text":"<p>What is CICD for network automation? The goal to to bring software development principles into the net devops mind frame.</p> <p>What is continuous deployment vs continuous delivery? - Delivery means to deploy all of your code changes to a testing and/or production environment after the build stage. You can schedule the config upgrade when ever. - Deployment mean that there is no human intervention. when the pipeline is passed the config change is pushed out immediately. No more release day.</p> <p>How is this done in practice? network as code network stored as source control changes are proposed in code  \"branches\" CICD builds test environment, tests code on test environment, then if successful the configuration change will be pushed out to end devices</p> <p>Tools you will need to preform this ( this is just a list i have come up with, this does not mean you need to follow the tools i have called out) - Ansible - CML - Github(Maybe, might try something else), gogs  - Drone or Jenkins - Vagrant is an option as well   - My understanding is that this will start up a local copy of cisco IOS and you can test out your configuration and verify the change worked how you thought it would.</p> <p>steps - create a branch - update network to code code - stage and commit your  - push your commits to the source control - pushing your commit to the dev branch, Your pipeline push a message to jenkins - Jenkins is a tool will run the CICD process   - You can start up a test network   - push out configuration changes to the test network   - Verify your change worked     - This one can be tedious and difficult to do     - You may have a lot of different tests that you want to run - Destroy your test network - if all tests pass, your CICD tool will merge the changes to your production environment - Depending on your choice of Continues deployment or delivery. this config change will get pushed out right away or on a schedule. - Once the change is pushed out, you will have your change </p> <p>Some notes on pipelines - Pipeline files are done in yaml - Not 100% sure on the next part but this is what i saw in the video i watched - Yaml file contains   - notify     - you may use slack, discord, teams, webex, ECT   - integration   - delivery   - deployment - CICD is not magic. you write out exactly what you want done and the CICD tool will do it - </p> <p>Many steps will be involved for this to happen. (here are some of the steps, need to think about it a bit more before. the steps right now will not be in order) - need a environment as a \"coded network\" - need to have copies of your network </p> <p>You need to first create your perfect test environment. AKA create a digital twin, then copy that XML data you receive and that will be a template that your workflow tool will use to build out the CML topology. (This will be a very tedious process at first but worth it in the end.)</p>"},{"location":"Developer%20Training/CICD%20Pipeline/#github-actions","title":"Github actions","text":"<p>Events - This is the trigger to start a workflow Jobs - Jobs consite of steps and actions Runners - This is a container enviroment that will run our code  - Default github will run this for you, but you have the option to host your own if you would like Steps - Steps are a list of actions that must be done actions</p> <p>for github the naming convention needs to be  repo name/.github/workflows/filename.yml</p> <p>when user updates sharepoint list, event is triggered.  power automate creates a either an issue or a PR that will update a Json file (might not be json, but it could be) I will also want a check to be done to see if user updated file correctly I need a PR to be created and I need someone to manually approve it inside of github. once approval and merge is complete.  CD will take into action and will go to service now to update the fields for the device type. testing will need to happen to to check see if device type is in snow, or dnac.</p>"},{"location":"Developer%20Training/Deploying%20Applications/","title":"Deploying Applications","text":""},{"location":"Developer%20Training/Deploying%20Applications/#cloud","title":"Cloud","text":"<p>NIST defines cloud as three main category with additional subcategories. They are: - Essential characteristics   - Broad network access   - Rapid elasticity   - Measured service   - On-demand self-service   - Resource Pooling - Service models   - SaaS   - PaaS   - IaaS - Deployment models   - Public   - Private   - Hybrid   - Community</p> <p>Some benefits of containers include: - Consistency for deployment automation - Simplified lightweight image files measured in MB rather then GB - Providing only what the app needs and nothing else - Ability to work the same production as in a developer's laptop - Ability to deploy applications in seconds</p> <p>Notes about serverless: - Of course there is still a server. but you dont need to work about the server at all. - This is the idea that you write code, upload the code to a server and the server just runs the code. - Works well if you just need a bit of code to run periodically. - Can also be called function as a service. - Advantages of serverless deployment   - Cost   - Scalability   - Easier to use and write code for - Disadvantages of serverless deployment   - Latency to spin up the service when needed   - Resource constraints   - Monitoring and debugging   - Security and privacy   - Vendor lock-in</p>"},{"location":"Developer%20Training/Deploying%20Applications/#devops","title":"DevOps","text":"<p>What is DevOps? A compound of development (Dev) and Operations (Ops), DevOps is the union of people, process, and technology to continually provide value to customers.</p> <p>DevOps guiding principles - Culture   - For DevOps to work, organizational culture must change.    - This is the most important and more difficult part of DevOps - Automation   - Everything that can be automated should be automated.  - Lean   - Reducing wasted efforts and streamlining the process. - Measurement   - If you never measure your results, you will never know what to improve or if you are improving. - Sharing   - Feedback and sharing is key to reach the ultimate goal. - Holistic   - The DevOps process needs to be treated as a whole process, rather than just a couple of smaller tasks.</p>"},{"location":"Developer%20Training/Deploying%20Applications/#putting-devops-into-practice-the-three-ways","title":"Putting devops into practice. The Three ways","text":"<p>First way: Systems and flow The following are key characteristics of the first way - Make work visible - Reduce batch sizes - Reduce intervals of work - Build in quality by preventing defects from being passed downstream </p> <p>Second way: Feedback loop The following are key characteristics of the second way - Amplify feedback to prevent problems from happening again - Enable faster detection and recovery - See problems as they occur and swarm them until they are fixed - Maximize opportunities to learn and improve</p> <p>Third way: Continuous Experimentation and Learning The following are key characteristics of the third way - Conduct dynamic, disciplined experimentation and risk taking - Define time to fix issues and make the system better - When things go wrong, don't point fingers - Create shared code repositories</p>"},{"location":"Developer%20Training/Deploying%20Applications/#devops-implementation","title":"DevOps Implementation","text":"<p>The stages for implementing DevOps generally follows these steps: - Continuous integrations   - This part involves merging dev code with production code and introduces automated testing. - Continuous delivery   - This stage involves a software package delivery mechanism for releasing code to staging for review and inspection. - Continuous deployment   - This stage relies on continuous integration and continuous delivery to automatically replace code into production as soon as it is ready.</p>"},{"location":"Developer%20Training/Deploying%20Applications/#components-of-a-cicd-pipeline","title":"Components of a CI/CD Pipeline","text":"<p>CI/CD - Continuous integration and continuous deployment CD/CD is the idea of developing, testing and deploying software in small batches. Your feature will be in a usable and being used will be much quicker when deploying in a CI/CD mindset.</p> <p>What is continuous deployment vs continuous delivery? - Delivery means to deploy all of your code changes to a testing and/or production environment after the build stage. You can schedule the config upgrade when ever. - Deployment mean that there is no human intervention. when the pipeline is passed the config change is pushed out immediately. No more release day.</p> <p>A CI/CD pipeline consists of: - Source code repository - Build stage ( source code, dependencies, and static code analytics) - Test stage ( unit and integration tests, end-to-end tests) - Deploy stage ( packaging, staging and production)</p> <p>A Gitlab pipeline consists of: - Commit: a change in the code - Job: Runner instructions - Pipeline: a group of jobs divided into different stages - Runner: A server or agent that implements each hob separately, which can spin up or down if needed. - Stages: Parts of a job(for exmaple, build or tests). Multiple jobs inside the same stage are executed in parallel.</p>"},{"location":"Developer%20Training/Model-Driven%20Programmability/","title":"Model Driven Programmability","text":"<p>Model-Driven Programmability</p> <p>gRPC is an open-source project started by Google to provide a modern remote procedure call framework that can be used in any environment.</p>"},{"location":"Developer%20Training/Model-Driven%20Programmability/#netconf","title":"NETCONF","text":"<p>NETCONF = Network Configuration Protocol NETCONF is just the connection and configuration protocol to a network device. If you need to send actual data, this is where YANG (Yet another next generation) steps in. With YANG you have a way to format your device data that you can push to your end devices. NETCONF uses SSH as its communication layer. It uses a client server model. NETCONF consists of four layers: - Content layer   - Actual config and notification data. - Operations layer   - defines a set of base protocol operations to retrieve and edit the config data - Message layer   - Provides a mechanism for encoding remote procedure calls. - Secure transport layer   - Ensures a secure and reliable transport between a client and a server. Messages sent with NETCONf use RPCs. - When you state an Message with a manager and an agent, The manager will send a RPC message with a unique ID. That unique ID will need to be in the REC-Reply in order for the manager to know that the agent and manager are talking about the same task. - Here is a copy of the netconf protocol stack  - Here is a sample of the NETCONf communications 1. Connect to device and say hello (Manager &gt; Agent) 2. Retrieve capabilities (Manager &lt; Agent) 3. Investigate abailable models, determine which to use 4. Compose operation get-config  5. send message rpc (Manager &gt; Agent) 6. Retrieve RPC-Reply (Manager &lt; Agent) 7. Process data</p>"},{"location":"Developer%20Training/Model-Driven%20Programmability/#netconf-operations","title":"NETCONF Operations","text":"Operation Description \\ Retrieve running configurations and device state information. \\ Retrieve all or part of the specified configuration data store. \\ Load all or part of a configuration to specified configuration data store. \\ Replace an entire configuration data store. \\ Delete a configuration data store. \\ Copy the candidate data store to the running data store. \\/\\ Lock or unlock the entire configuration data store system. \\ Gracefully terminate the NETCONF session. \\ Forcibly terminate teh NETCONF session. <p>The NETCONF \\ operations supports several attributes - merge - replace - create - delete"},{"location":"Developer%20Training/Model-Driven%20Programmability/#python-with-netconf","title":"Python with NETCONF","text":"<ul> <li>When using netconf inside of python you need to use ncclient. You will need to import manger module. This module will be used to connect to the device.</li> <li>You will often need to find out what capabilities the agent can support. There are a few different ways to accomplish this. One way is by pulling the data from the agent itself. The problem here is that the data you get back might be hard to read. Another option will be to go to the vendors website and read about it. This is my preferred method.</li> <li>Interface container will allow you configure the device or gather data about the config. The interface-state container will tell you stats about the interface.</li> <li>You will also likely want to use another module called \"xmltodict\" This does exactly what it says. converts xml to a dictionary. </li> </ul>"},{"location":"Developer%20Training/Model-Driven%20Programmability/#yang","title":"YANG","text":"<p>YANG = Yet another next generation YANG is a standardized data modeling language used to model configuration and state data. YANG is used to NETCONF. YANG is expressed in XML. A native YANG model is created be a vendor for their equipment. often times one native model is not compatible with other vendors hardware/software. A YANG module contains three types of statements: - Module header statements describe the module and give information about it. - Revision statements provides information about the history on the module. - Definition statements are the body of the module, where the data model is defined.</p> <p>YANG defines four types of nodes for data modeling: - Leaf nodes   - Leaf nodes only have one value of a specific type   - Example is a single interface - Leaf-list nodes   - Leaf-list are a list of leaf nodes   - example trunk interfaces - Container nodes   - Container is used to group related nodes within a subtree   - Example would be stats about an interface. there are many different stats that you can grab from that one container. - List nodes</p> <p>Components that go into building the YANG data model - Header information - Imports and includes - Type definitions - Configurations and operation data declarations - Action (RPC) &amp; notification declaration</p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/","title":"Network Engineer Modules","text":""},{"location":"Developer%20Training/Network%20Engineer%20Modules/#connection-based-modules","title":"Connection based Modules","text":"<p>scrapli (core) - </p> <p>request</p> <p>ncclient: This python library helps with client-side scripting and application integration for the NETCONF protocol.</p> <p>Netmiko: This module helps to make SSH connections, this for network devices. This really only supports the major vendors.</p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#configuration-management","title":"Configuration Management","text":"<p>napalm: napalm (Network automation and programmability abstraction layer with multi-vendor support) is a python module that provides functionality that works in a multi-vendor fashion.</p> <p>scrapli (extensions) - </p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#inventory-management-and-orchestration","title":"Inventory Management and orchestration","text":"<p>nornir: This is an extendable, multithreaded framework with inventory management to work with large number of network devices. This also works with your configuration platform. Just remember that nornir is a pythonic way of doing many tasks to many devices at one time, and a way of managing your inventory.</p> <p>Ansible:</p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#parsers-and-data-interpreters","title":"Parsers and Data interpreters","text":"<p>Genie (PYATS)</p> <p>xmltodict &lt;&lt; These two are more generally used because of their ease of use. untangle minidom ElementTree &lt;&lt; These two are more generally used because of their ease of use.</p> <p>pyyaml ruamel.yaml &lt;&lt; Currently this one is newer and better maintained.</p> <p>pyang</p> <p>json</p> <p>csv</p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#unit-testing","title":"Unit testing","text":"<p>pyats</p> <p>unittest</p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#operating-system","title":"Operating system","text":"<p>sys: This module allows you to interact with python interpreter and manipulate and view values.</p> <p>os: This module gives you access to the underlying operating system environment and file system. </p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#other","title":"Other","text":"<p>ipaddress module</p> <p>pprint</p> <p>pysnmp</p> <p>datetime</p> <p>time</p>"},{"location":"Developer%20Training/Network%20Engineer%20Modules/#additional-notes","title":"Additional Notes","text":"<ul> <li>Scrapli</li> <li>core<ul> <li>pip install scrapli[genie]</li> </ul> </li> <li>nonir_scrapli</li> <li>scrapli_community<ul> <li>This is for if you want to support addtional plateforms that are not supported by core.</li> </ul> </li> <li>scrapli_cfg</li> <li>scrapli_replay</li> <li>scrapli_netconf</li> </ul>"},{"location":"Developer%20Training/Software%20Development%20Practices/","title":"Software development lifecycle","text":""},{"location":"Developer%20Training/Software%20Development%20Practices/#what-is-sdlc-software-development-lifecycle","title":"What is SDLC (Software development lifecycle)?","text":"<p>SDLC is a generic process. The following is the overall stages - Stage 1 - Planning   - Can also be called requirement analysis. Identify the problem, get input from stakeholders. - Stage 2 - Defining   - What should your program do at the end? - Stage 3 - Designing   - You turn software specifications into a design specification. Users must have buy in at this stage - Stage 4 - Building   - This is where you start to work on the code. - Stage 5 - Testing   - Test code for bugs or defects. - Stage 6 - Deployment   - This is where you put your software into production.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#software-development-methods","title":"Software Development methods","text":""},{"location":"Developer%20Training/Software%20Development%20Practices/#waterfall","title":"Waterfall","text":"<p>Waterfall is the older way of designing code. This method follows the SDLC down to a T. The problem is that you do not deliver a product until it is completed. You may spend years writing the code before ever pushing the code into production. if you are halfway done writting the code, you still have delivered 0 product. Waterfall does not handle changes well at all. If need to make a change during the coding phase, that might mean you need to take a step backwards and move back into planning. Advantages: - Design errors are highlighted before any code is written - Good documentation is mandatory for this kind of methodology Three major challenges for waterfall include - The serial nature of waterfall - Value is not achieved until the end - Quality can often suffer. Re-engineering the applications can be very costly.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#lean","title":"Lean","text":"<p>According to the lean pioneers, an enterprise must focus on three major points to fully embrace the lean philosophy. - Purpose - Process - People Three main goals for the lean method - Elimination of waste   - if something doesn't add value to the final product. Get rid of it - Just-in-time   - Don't build something until the customer is ready to buy it. - Continues improvement   - Always improve your processes with lessons learned.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#agile","title":"Agile","text":"<p>One key factor of agile, is breaking your work into short sprint(2 weeks is typical). At the end of every sprint, you should have something to deliver to your program. You would first create the bare minimum viable product. This may not deliver every part of your whole product, but you just delivered a product to your users that can start to be used right away. At the end of the next sprint you will have another feature, and the next sprint you will have another feature. You will continue to deliver products over and over again, while finding bugs along the way. You may also find out that one of the original goals will need to be scraped. This is no longer a big deal because you may have not spent time writing this code and you just ended up saving yourself a bunch of time.</p> <p>The Agile Manifesto - Customer satisfaction is provided through early and continuous delivery of valuable software. - Changing requirements, even in late development, are welcome. - Working software is delivered frequently (in weeks rather than months). - The process depends on close, daily cooperation between business stakeholders and developers. - Projects are built around motivated individuals, who should be trusted. - Face-to-face conversation is the best form of communication (co-location). - Working software is the principal measure of progress. - Sustainable development requires being able to maintain a constant pace. - Continuous attention is paid to technical excellence and good design. - Simplicity\u2014the art of maximizing the amount of work not done\u2014is essential. - The best architectures, requirements, and designs emerge from self-organizing teams. - A team regularly reflects on how to become more effective and adjusts accordingly.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#software-testing","title":"Software testing","text":"<p>There are different types of testing - Unit testing   - This is to test out very small bits of your code. - Integration tests   - This is to find how your application can work with other applications.  - Function test or system testing   - This test will do full end to end testing. Testing everything. This will be the longest phase of your testing. - Acceptance testing   - Test if the system is read for delivery.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#test-driven-developmenttdd","title":"Test-Driven Development(TDD)","text":"<p>Developing test before writing code seems backwards but it is a standard when writing code. If you write test first you can avoid some unnecessary bug chasing. The five steps of TTD 1. Write tests 2. Test fails 3. Write code 4. Test passes 5. Refactor</p> <p>Robust tests are very important, as they will help you discover the edge cases. Refactoring your code is important, here are some reasons why - Better code structure - Better code readability - Better design</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#unit-testing","title":"Unit testing","text":"<p>Unit testing is the idea of testing out very small parts of your code. The idea is that if you test out every small part of code and that failure happens, you can quickly take a look. Where if you test out all the code at one time, you may need to test to run for 10-20 minutes before the failure happens. running that over and over again could take hours.</p> <p>Good unit tests should have the following characteristics - Reliable - Isolated - Fast - Readable</p> <p>Tested units usually have dependencies to other parts of the system, in order to isolate your unit tests you may need to create a test double. Test doubles is a object that mimics some aspects or functionality of some other object. Types of test doubles include: - Fake - Stub - Mock - Dummy - Spy</p> <p>When creating unit test its a good idea to create your test using the OOB principles. Another good idea is to name your test at \"test_testmodulename\". You will need to import unittest and when creating your class you will need to inherit unittest.Testcase from the unittest module. If you want to run your test make sure to add the following to your code. - <code> if __name__ =='__main__': \u00a0\u00a0\u00a0\u00a0unittest.main() </code></p> <p>** NOTE go to the following site to learn more info about unit test. https://docs.python.org/3/library/unittest.html</p> <p>Some tools for TDD and unit testing - pyats - unittest</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#integration-testing","title":"Integration testing","text":"<p>This is the idea of testing units of code with their necessary integrations. A couple different approaches include - Big bang approach - Incremental approach   - Three different directions     - Top-down approach     - bottom-up approach     - sandwich approach</p> <p>Two different test double types for integration testing - Driver - Stub</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#system-testing","title":"System testing","text":"<p>The idea of system testing is to test the application end to end. There are many types of testing for system testing, some of those tests include - Functionality testing - Installation testing - Usability testing - Security testing - Performance testing - Load testing - Stress testing - Regression testing - Storage testing - Configuration testing: A given system could be running in the cloud, on local computer, remote servers, ect. This testing it to test the different types of configuration. - Compatibility testing - Reliability testing: check new versions of code work with old versions. - Recovery testing - Procedure testing</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#acceptance-testing","title":"Acceptance testing","text":"<p>This portion of testing is working the the actual end users. Different level of testing here includes - Alpha testing - Beta testing - Contract testing - Regulation testing - Operational testing</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#code-review","title":"Code review","text":"<p>Code review is a way to have other developers look at your code for verification. Some facets for what other developers will be looking for include  - identify bugs   - This is the most important part of the code review - Improve code quality - make sure standards are being followed - allows others to be familiar with other parts of the project</p> <p>Often multiple people are assigned to perform a code review. It is best to verify smaller bits of code, in order to keep it more manageable.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#design-patterns","title":"Design Patterns","text":""},{"location":"Developer%20Training/Software%20Development%20Practices/#understanding-design-patterns","title":"Understanding Design patterns","text":"<p>You write this to show exactly what you are trying to accomplish. A design pattern is a map. This is not code. a set of rules on how you can write code.</p> <p>take a look at the following book: Design patterns: element of reusable object-oriented software ISBN-13: 978:021633610</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#unified-modeling-language","title":"Unified Modeling Language","text":"<p>Unified modeling language (UML) was created because programming languages are usually not at a high level of abstraction. UML helps software designers look at a UML glass diagram and understand better how the application is suppose to function. </p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#architecture-patterns","title":"Architecture patterns","text":"<p>Some of the commonly known software architecture patterns: - Layered or multitier architecture pattern   - This is broken up almost like an org chart.   - There is no rule as to how many layers you can help, but often you will find 4 layers     - Presentation layer       - User interface communication     - Business layer       - Business rules processing     - Persistence layer       - Data persistence handling     - Database layer       - Database storage technology   - You should not skip or jump layers, if a request starts at the presentation layer it must go through business and persistence to get to the database layer.   - if for some reason you did need a special layer that is optional to use or not, you would create an  open-type layer   - each layer should be designed independently  - Event-driven architecture pattern - Microservices architecture pattern - Model-View-Controller (MVC) architecture pattern - Space-based architecture</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#software-design-patterns","title":"Software Design Patterns","text":"<p>There are many software design patterns, and you should pick out the correct one for your application. There are three groups in which patterns are divided into.  - Creational   - concerned with the class or object creation mechanism - Structural   - deals with class or object compositions for maintaining flexibility in larger projects - Behavioral   - describes the ways of interaction between classes and objects.</p> Creational patterns Structural patterns Behavioral Patterns Singleton Adapter Observer Abstract Factory Decorator Interpreter Prototype Facade Mediator Factory Method Proxy State"},{"location":"Developer%20Training/Software%20Development%20Practices/#singleton-design-pattern","title":"Singleton Design pattern","text":"<ul> <li>A pattern that restricts classes to only being instantiated once during the execution of a program.</li> <li>Examples include - Data base connections, configuration values, static values, ect</li> <li>A class with a private instance variable representing it's only instance, a public get instance() method to retrieve that object, a constructor to enforce a single-instantiation.</li> <li>Extra steps are needed to make a singleton design work. other languages like java and c# will work automatically.</li> <li>Example code view Sample code/singleton.py</li> </ul>"},{"location":"Developer%20Training/Software%20Development%20Practices/#observer-pattern","title":"Observer Pattern","text":"<p> A pattern where dependent objects are updated or modified by one or more subject objects - Allows objects to react or respond in response to events. - Popular in UI systems - The observer pattern is often used to handle communication between the model and the view in the MVC pattern.</p> <p>Two classes defined by observer pattern: - Subject - Which maintains a list of observers and includes methods for attaching, detaching, and notifying observers. - Observer - Which has a method to receive updates from subjects. - Example code view Sample code/observer.py</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#model-view-controller-mvc","title":"Model, View, Controller (MVC)","text":"<p>A high-level abstraction where responsibilities are divided up into three loosely coupled components. This design type is often used in web development. - Model: The component that retrieves and manipulates the data. Often tied to a database. - View: The component that displays data. It's what the end users see on their devices.  - Controller: The component that handles logic flow, user interaction, and directs models and views.</p> <p>Benefits of the MVC pattern: - Separation of concern - Multiple views to the same model - Flexible presentations changes - Independent testing of components - Pluggable components</p> <p>Downsides of the MVC pattern: - Increased complexity - Excessive number of change notifications - View and controller tight coupling - Separate controller is sometimes not needed</p> <p>Good to know - There is typically one controller for each view.  - One of the primary features of MVC architecture is the separation between the view and the model. This is very important design principle. - The relationship between the view and a controller is an example of the strategy design pattern.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#conducting-code-reviews","title":"Conducting code reviews","text":"<p>Some benefits for a code review - It helps you create higher-quality software. - It enables your team to be more cohesive and deliver software projects on time. - It can help you find defects and inefficient code.</p> <p>Some good practices for code review - Use a code review checklist. Make sure you are following your organization standards. - Review the code not the person. - Check your ego at the door. Remember people are not reviewing you they are just looking at your code. - make sure your complete the recommendation and your check those back into the repo.</p>"},{"location":"Developer%20Training/Software%20Development%20Practices/#other-notes","title":"Other Notes","text":"<p>Cohesion and loosely coupled  Here are some design guidelines to consider: - Acyclic dependencies principle - Stable dependencies principle - Single responsibility principle</p> <p>The concepts that define what OOP enables: - Abstraction - Encapsulation - Inheritance - Polymorphism</p> <p>A decision on software architecture can be made while studying these characteristics of a system: - Performance - Availability - Modifiability - Testability - Usability - Security</p>"},{"location":"Developer%20Training/Tips%20for%20VSCode/","title":"Tips for VSCode","text":"<p>Move explorer to the right side. Toggle sidebar positions.</p> <p>control+b to hide your explorer</p> <p>open command pallet. Control+shift+p</p> <p>you can change your color theme. after you type in theme selector you can also download theme extensions. </p> <p>control, will open your settings. you can change things like font type or size. font ligatures can clean up your style and install of creating a double equals sign. you could create a very long equal sign. really this part just makes it look prettier to you.</p> <p>You can have icon themes to also make your icons look nicer. also will give you the ability to very quickly identify what a file type is by looking at the icon. (Preferences: file icon theme). you can also install icons from extensions.</p> <p>You can enable white spaces to allow you to see if there are the correct number of white spaces you want.</p> <p>you can enable tab to mean spaces instead of a normal tab</p>"},{"location":"Developer%20Training/Vagrant/","title":"Vagrant","text":"<p>What is Vagrant - My understanding is that this will start up a local copy of cisco IOS and you can test out your configuration and verify the change worked how you thought it would.</p> <p>How does it work? not sure yet...  </p>"},{"location":"Developer%20Training/Version%20Control%20and%20Git/","title":"Version control","text":""},{"location":"Developer%20Training/Version%20Control%20and%20Git/#what-is-version-control","title":"What is Version control?","text":"<p>Version control is the ability to produce code to a repository and keep the history of all the changes made to that code. I should be able to go years back and look at a commit, to find out what changes were made with that one commit. </p>"},{"location":"Developer%20Training/Version%20Control%20and%20Git/#advantages-to-version-control","title":"Advantages to version control?","text":"<ul> <li>Version control allows multiple develops to work on the same code and avoid the problem with document locking.</li> <li>You can look through all the code changes and compare commit to commit to see the differences.</li> <li>You can branch and merge your code. which will allow you to work on code in an isolated environment. You can change code without hurting the main software. This will also help you to avoid conflicts, meaning that if you and someone else and editing the same line of code, you will not have to worry ( at least right now) about you change impacting their work. </li> </ul>"},{"location":"Developer%20Training/Version%20Control%20and%20Git/#git","title":"Git","text":"<p>What is Git?   - Git is a type of version control.   - Git tracks changes to source code.   - Git is a distributed version control system. Meaning everyone has a full copy of all the source code.   - Github is a common platform for developing code. Keep in mind that Git and Github are two different items. Understanding how git works   - Git keeps a running history of every commit you make. This history (called a snapshot in git terms) details all the changes to the software over time and ensure the integrity o this record by using SHA-1 hash.   - This has is 40 character string. It is possible that two commits could have the same hash, but that likelihood is almost impossible Fun notes - The standard user friendly commands are called \"porcelain\" commands. The more complicated inner workings of git are called \"plumbing\". - Where ever the head is pointing is where you are currently working. if the head was pointed to 2 commits back you are working on code that is two commits old.</p>"},{"location":"Developer%20Training/Version%20Control%20and%20Git/#git-tree-structure","title":"Git tree structure","text":"<ul> <li>Local workspace</li> <li>This is where you store source code</li> <li>Staging area</li> <li>This is an intermediary storage area</li> <li>Head, or local repository</li> <li>This is where you store all committed items.</li> </ul>"},{"location":"Developer%20Training/Version%20Control%20and%20Git/#git-file-status","title":"git file status","text":"<ul> <li>Untracked</li> <li>When you first create a file the file starts in untracked mode</li> <li>Unmodified</li> <li>this is where git watches the file but file has been unchanged</li> <li>Modified</li> <li>This is where you edit a file for your repo</li> <li>Staged</li> <li>at this point your files has been committed. Now that the file has been committed the file moves back to unmodified status.</li> </ul> <p>basic Git commands/terminology</p> <p>create these first when you want to pull down config. This is meta data about yourself, needed for git commands later on.   - git config --global user.name \"Your Name\"   - git config --global user.email \"your_email@whatever.com\"</p> <p>Creating a new repository   - create a directory     - mkdir train_git     - cd train_git     - touch \"hello_world.txt\"   - create a new repository     - git init        - This will create a repository for your project. That repository is stored on your computer.     - git add hello_world.txt       - This will create a snapshot of the project. you can add a single file or many files. This didn't create the snapshot. this is just the first step. this is actually called the index in git.     - git commit -m \"adding first file\"        - This will create a snapshot from your index, and this will add to your repository. good practice to give details about this commit. you should only commit the files that you want to change.       - git message tips and tricks (https://chris.beams.io/posts/git-commit/)         - separate subject line from body with a blank line          - limit the subject line to 50 characters         - Capitalize the subject line         - Do not end teh subject line with a period         - use the imperative mood in the subject line          - Wrap the body at 72 characters         - Use the body to explain what and why vs how</p> <p>Data about your current git project ( I cant think of a better name yet.)    - git log      - this will show the history of the snapshot     - git log -(number)        - this will show a certain number of commits     - git log --oneline       - shortens to one line showing commit message and hash code     - git log --stat        - shows number of lines that changed with each commit      - git log --diff       - shows all the differences in the commits   - git status      - This will tell you if your file are committed in your repository.     - You can put a --short or -s and you will see a shorter list of your current status ( kinda nice when you do this via cli)   - git diff (some commit id) (some other commit id )     - this will show the differences in the git snapshots. if you want to see the differences in your commits your must put the commit code. you only need to see the first few digits and not the whole code.     - if you add a --staged you will see a difference between your committed files and your staged files      - if you want to see a difference in your working directory that has not been staged, just use a git diff.     - if you add --cached : This command shows any changes between the index and your last commit   - git reset     - this will allow us to throw changes away      - allows us to move commits from history to our working or staging area     - can be a destructive command     - three real options       - use a --soft (commit-ID), move commit to staging area       - use a --mixed (commit-ID), move commit to the working directory        - use a --hard (commit-ID), this will move you commits to the trash</p> <p>Adding a file to the commit git commit   - good practice is to keep your commit messages under 50 characters    - git commit -m \"your short message\"</p> <p>Adding/removing/Move a file git add (file name or directory location)   - Also called Git stages   - This is stage your commit and get them ready for committing your change   - You want to stage like code changes together and commit those changes at one time because you can add notes and look at different commits when auditing the code.   - git add . or -A : Adds everything in the entire local workspace   - git add {filename} : Adds a single file git remove (file name or directory)   - git rm (-r) (-f) {directory/file}   - this will stop tracking a file/delete the file   - Adding a --cached file name will stop tracking the file but will not remove it git move   - git mv (-f) {source} {destination}   - This will move a file from one location to another location.   - When you use this command you will not need to git add to add the file to a staging area. git stash {parameters} - temporarily store modified tracked files - This is a good way to store your files quickly without doing a git commit. - git stash pop brings your files back to the main workspace for you.</p> <p>What is a Branch?   - is a way of taking your code and branching off of your main code.   - exactly like a tree Creating a new branch   - to add a new branch - git branch {branchname}   - to delete a branch - git branch -d {branchname} Moving toa  new branch   - git checkout -b {branchname} What is a conflict?   - if two commits change the same line of code. you can have a conflict in that code.</p> <p>git merge    git merge (main-branch)   - this will allow you to keep two different versions of code and keep one as you main and the other as your different set of features. (kind of hard to explain for me.)   - if you have an app. one paid version of the app and the other free version. if you wanted all you paid version of the app to have all the same features of your free version plus some extra features. you would do the following.     - You would have two branches -Free -Paid     - you would then switch to your paid version     - You would then merge to your free version     - doing this would allow you to take all your code from the free version and have it in your paid branch     - But it would not work in reverse. your free version would not have the features from your paid version.   - some terminology     - Target branch - The branch of where the changes are being pulled from     - Receiving branch - The branch where your changes are being pulled into.   - Conflicts in file changes need to be resolved manually   - You will often use a git merge and git fetch together.</p> <p>Fast forward merge           --0--0--0 &lt;- master branch          /   --0--0/</p> <p>3-way merge        ---0-0--0--        /          \\       /            \\       --0--0----0----0----0-- Master</p> <p>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</p> <p>git clone \"hyperlink\"    - this is copy a git repository to your computer</p> <p>git pull   - this will pull the updates from a online repository branch to your local repository and merge the branch.</p> <p>git pull request   - This one messed with my head for a while, the following is the best way I think to explain it   - if you make a change to someone else's source code and you want that change to be in the source code you submit a pull request.   - Meaning you are asking them to pull your changes into their code.</p> <p>git remote {parameters} - Manage remote repositories.</p> <p>git branch </p> <ul> <li>To understand this it really helps to understand how pointers work or cnames</li> <li>a Cname is just an alias that points to the main domain name. you can make changes to the cname and never update the original record.</li> <li>In this case i can creating an alias of the code, updating the alias. Then later i may ask my branch to update the main code</li> <li>This actual code will show the branches i have, or i can create and delete my branches </li> </ul> <p>git fetch    - Fetches changes from the remote repository.   - Fetch will be used to get the remote branches   - Fetch will get changes and store them in your local repository, a git pull will merge those changes</p> <p>The only two reasons i would use this next part is   - because I dont want to log into the gui   - I want to change my repository name</p> <p>Glossary Repository is a directory that is initalized with git. It is where a all your files are stored.</p>"},{"location":"Developer%20Training/git%20training/","title":"Git training","text":"<p>What is Git?   - Git allows you to have version control of your software.   - Git tracks changes to source code.</p> <p>Why do you need git?   - git allows sharing code amongst developers</p> <p>basic Git commands/terminology</p> <p>create these first when you want to pull down config. This is meta data about yourself, needed for git commands later on.   - git config --global user.name \"Your Name\"   - git config --global user.email \"your_email@whatever.com\"</p> <p>Creating a new repository   - create a directory     - mkdir train_git     - cd train_git     - touch \"hello_world.txt\"   - create a new repository     - git init        - This will create a repository for your project. That repository is stored on your computer.     - git add hello_world.txt       - This will create a snapshot of the project. you can add a single file or many files. This didn't create the snapshot. this is just the first step. this is actually called the index in git.     - git commit -m \"adding first file\"        - This will create a snapshot from your index, and this will add to your repository. good practice to give details about this commit. you should only commit the files that you want to change.       - git message tips and tricks (https://chris.beams.io/posts/git-commit/)         - separate subject line from body with a blank line          - limit the subject line to 50 characters         - Capitalize the subject line         - Do not end teh subject line with a period         - use the imperative mood in the subject line          - Wrap the body at 72 characters         - Use the body to explain what and why vs how</p> <p>Data about your current git project ( I cant think of a better name yet.)    - git log      - this will show the history of the snapshot     - git log -(number)        - this will show a certain number of commits     - git log --oneline       - shortens to one line showing commit message and hash code     - git log --stat        - shows number of lines that changed with each commit      - git log --diff       - shows all the differences in the commits   - git status      - This will tell you if your file are committed in your repository.     - You can put a --short or -s and you will see a shorter list of your current status ( kinda nice when you do this via cli)   - git diff (some commit id) (some other commit id )     - this will show the differences in the git snapshots. if you want to see the differences in your commits your must put the commit code. you only need to see the first few digits and not the whole code.     - if you add a --staged you will see a difference between your committed files and your staged files      - if you want to see a difference in your working directory that has not been staged, just use a git diff.   - git reset     - this will allow us to throw changes away      - allows us to move commits from history to our working or staging area     - can be a destructive command     - three real options       - use a --soft (commit-ID), move commit to staging area       - use a --mixed (commit-ID), move commit to the working directory        - use a --hard (commit-ID), this will move you commits to the trash   - git rm (file name)     - this will stop tracking a file/delete the file     - Adding a --cached file name will stop tracking the file but will not remove it</p> <p>git checkout (newer versions of git can use a get switch)   git checkout (some commit id)   - this will allow you to change between commits   - this will take that commit and puts in our file system   - in doing this you can grab your old commit that was working and have it fix a new bug that you may have introduced    git checkout (branch-Name) or git switch (branch-Name)   - This will allow you to Branch your code   - When using the -c flag with git switch it will create a branch and switch it over the to new branch.   - </p> <p>git merge    git merge (main-branch)   - this will allow you to keep two different versions of code and keep one as you main and the other as your different set of features. (kind of hard to explain for me.)   - if you have an app. one paid version of the app and the other free version. if you wanted all you paid version of the app to have all the same features of your free version plus some extra features. you would do the following.     - You would have two branches -Free -Paid     - you would then switch to your paid version     - You would then merge to your free version     - doing this would allow you to take all your code from the free version and have it in your paid branch     - But it would not work in reverse. your free version would not have the features from your paid version.   - some terminology     - Target branch - The branch of where the changes are being pulled from     - Receiving branch - The branch where your changes are being pulled into.   - Conflicts in file changes need to be resolved manually   - How to resolve conflicts?     - multi-step process     - Git tells you which file.     - you need to open file and fix conflict.       - You pick which changes you want. head is the one you are merging into, the other branch shows the code you are trying to merge in.       - remove the conflict markers and save the new file and create a commit.     - commit the fixed conflict.  </p> <p>Fast forward merge           --0--0--0 &lt;- master branch          /   --0--0/</p> <p>3-way merge        ---0-0--0--        /          \\       /            \\       --0--0----0----0----0-- Master</p> <p>What is a Branch?   - is a way of taking your code and branching off of your main code.   - exactly like a tree</p> <p>What is a conflict?   - if two commits change the same line of code. you can have a conflict in that code.</p> <p>What is HEAD? - HEAD is essentially a pointer. if you switch from working on branch main to a branch called new_branch. then HEAD is moved from main to new_branch.</p> <p>What is a detached head? - You are pointing head at a specific commit and not at a branch reference in your repo.</p> <p>How to reattach your head. - You can switch to a branch and that will fix the detached head state. - You can switch to a commit and then create a new branch which will fix HEAD again.</p> <p>One way to undo changes to a file is to use the following command - git restore  <p>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</p> <p>git clone \"hyperlink\"    - this is copy a git repository to your computer</p> <p>git pull   - this will pull the updates from a online repository to your local repository.</p> <p>git pull request   - This one messed with my head for a while, the following is the best way I think to explain it   - if you make a change to someone else's source code and you want that change to be in the source code you submit a pull request.   - Meaning you are asking them to pull your changes into their code.</p> <p>git add (file name or directory location)   - Also called Git stages   - This is stage your commit and get them ready for commiting your change   - You want to stage like code changes together and commit those changes at one time because you can add notes and look at different commits when auditing the code.</p> <p>git branch </p> <ul> <li>To understand this it really helps to understand how pointers work or cnames</li> <li>a Cname is just an alias that points to the main domain name. you can make changes to the cname and never update the original record.</li> <li>In this case i can creating an alias of the code, updating the alias. Then later i may ask my branch to update the main code</li> <li>This actual code will show the branches i have, or i can create and delete my branches </li> </ul> <p>git pull vs git fetch    - A git fetch will pull down changes from the remote repo and put them into out local repo. The local repo is where a change goes once you have committed it. Those changes are not integrated into our working files.   - A git pull will pull down the changes from the remote repo and install them into our workspace.</p> <p>What is a git remote? - Before we can push anything to Github we need to talk git about the remote repo on github. We need to setup a destination to push to. - In git, we refer to these destinations as remotes. Each remote is simply a URL where a hosted repo lives. - git remote or git remote -v - when creating a new remote (which if you use a git clone this will happen automatically for you) use the following command. git remote add {name} {url} - When you see \"origin\" that </p>"},{"location":"Developer%20Training/git%20training/#git-rebase","title":"Git rebase","text":"<p>What is git rebase? - Its a way to avoid doing merge commits.  - Example - You are working on a branch and you want your branch to include the changes that were made to your main branch. normally you need to do a git pull to update your working files. then you need to merge the changes from main into your branch. when you do this merge you must create a kind of useless commit that is just a merge commit. and you may need to do this many many times as you keep working on your branch - instead you can do a rebase and that allow you to skip doing a merge commit and essentially pull the changes from main into your branch without the commit.</p> <p>What is the use case for git rebase? - There are two main ways to use the git rebase command:   - as an alternative to merging   - as a cleanup tool</p> <p>When should you not use rebase? - Golden rule - Never rebase commits that have been shared with others. if you have already pushed commits up to github... DO NOT rebase them unless you are positive no one on the team is using those commits.</p>"},{"location":"Developer%20Training/Docker%20training/Docker/","title":"Docker","text":""},{"location":"Developer%20Training/Docker%20training/Docker/#docker","title":"Docker","text":"<p>What is docker? Docker is a containerization platform. You can take your application and run it on any OS that can run docker. Docker image will consist of all the componants you need to run an application. Docker also helps with tools to manage your containers.</p>"},{"location":"Developer%20Training/Docker%20training/Docker/#understanding-docker","title":"Understanding Docker","text":"<p>Docker containers use two capabilities in the linux kernel:  </p>"},{"location":"Developer%20Training/Docker%20training/Docker/#namespaces","title":"Namespaces","text":"<p>Namespaces are essential for providing isolation for containers. Six namespaces are used for this purpose - mnt (mountpoints): This namespace is used for mapping access to host operating system storage resources to the container process. - pid (processes): This namespace is used to create a new process ID for an application. - net (network): This namespace is responsible for network access and mapping communication ports. - ipc (System V IPC): Inert-process communications controls how the application can access shared memory locations between applications within containers. - uts (hostname): This namespace controls host and domain names, allowing unique values per process. - user (UIDs): This namespace is used to map unique user rights to processes</p>"},{"location":"Developer%20Training/Docker%20training/Docker/#cgroups","title":"Cgroups","text":"<p>Cgroups or control groups are used to mange resource consumption for each container. These values can be tweaked to limit how much resources a container can use at one time.</p>"},{"location":"Developer%20Training/Docker%20training/Docker/#docker-architecture","title":"Docker Architecture","text":"<p>The docker engine is the central component of the docker architecture. Docker architecture consists of three primary parts: the client, the docker host and the docker registry. - The client is a command-line utility that talks to the REST API of the Docker daemon. The client can communicate to a local or remote docker instance. - The Docker host is where the Docker daemon resides. The Docker daemon is a service that runs on the host operating system. - The registry is a place to store container images; it is also known as the repository for the container infrastructure. </p>"},{"location":"Developer%20Training/Docker%20training/Docker/#using-docker","title":"Using Docker","text":"<p>Working with containers When working with containers, the key commands are as follows: - create: Create a container from an image - start: start an existing container - run: create a new container and start it. - ls: list running containers. - inspect: get detailed information regarding the container. - logs: Print run logs from the containers's execution. - stop: Gracefully stop running the container. - kill: Stop the main process in the container abruptly. - rm: Delete a stopped container.</p> <p>Dockerfiles A Dockerfile is a script that is used to create a container image to your specification. A Dockerfile is simply a text file with a structured set of commands that Docker executes while building this image. Some of the most common commands are as follows: - FROM: Selects the base image used to start the build process or can be set to scratch to build a totally new image. - MAINTAINER: Lets you select a name and email address for the image creator. - RUN: creates image layers and executes commands within a container. - CMD: Executes a single command within a container. Only one can exist in a Dockerfile. - WORKDIR: Sets the path where the command defined with the CMD is to be executed. - ENTRYPOINT: Executes a default application every time a container is created with the image. - ADD: Copies the files from the local host or remotely via a URL into the container's file system. - ENV: Set environment variables within the container. - EXPOSE: Associates a specific port for network binding. - USER: Sets the UID for a user that is to run the container. - VOLUME: Sets up shareable directory that can be mapped to a local host directory. - LABEL: Provides a label to identify the created Docker image.</p> <p>Docker Images When working with Docker images, you primarily use the following commands: All start with commands start with \"docker image\" - build: Builds an image form Dockerfile. - push: Pushes a local image to an remote registry for storage and sharing. - ls: List images stored locally. - images: This will show a list of the local docker images. - history: Shows the creating and build process for an image. - inspect: Provides detailed information on all aspects of an image, including layer detail. - rm: Deletes an image from local storage.</p> <p>Actually building a docker file - Create the docker file - run the following command \"docker build  -t dockerfile:latest .\" - run the docker container with the following command \"docker run -d -p 5000:5000  dockerfile\"</p> <p>Here is an example of a simple dockerfile  </p> <pre><code>FROM ubuntu:18.04  \nMAINTAINER Adam Angell  \nRUN apt-get update -y &amp;&amp; apt-get install -y   python3-pip python3-dev  \nCMD [ \"ufw allow 5000\" ]  \nCOPY ./requirements.txt /app/requirements.txt  \nWORKDIR /app  \nRUN pip3 install -r requirements.txt  \nCOPY  ./myAPI.py /app  \nENTRYPOINT [ \"python3\" ]  \nCMD [ \"myAPI.py\" ]  \n</code></pre> <p>Steps to add container to the dockerhub  </p> <pre><code>docker tag \"image ID\"  \"name of dockerhub repo\":latest  \ndocker push \"name of dockerhub repo\"\n</code></pre>"},{"location":"Developer%20Training/Kubernetes%20training/Container%20types/","title":"Container types","text":"<p>There are multiple container types. these include - LXC - LXD - LXCFS - and more</p> <p>Docker uses LXC containers. </p> <p>keep in mind the following an OS is comprised of two things the OS kernel and software. The kernel is was interacts with the hardware. software is what interacts with the kernel drivers, user interfaces, gui, ect. Containers share the underlying kernel. You are not able to run a windows docker container inside a linux kernel. </p> <p>Docker does not have as much isolation between docker containers, VMs on the other hand do have true isolation from each VM.</p>"},{"location":"Developer%20Training/Kubernetes%20training/Kubernetes%20Architecture/","title":"Kubernetes Architecture","text":"<p>What is a node? it is a machine. it is a worker machine. This is what will be launched by Kubernetes.</p> <p>What is a cluster? A cluster is a set of nodes grouped together.</p> <p>What is a Master? A Master is a node with kubernetes installed and is configured as the master. The master will watch over the other nodes and is responsible for the actual orchestration over the other nodes.</p> <p>When you install kubernetes on a system, you are actually installing the following components. - Api server - This is the front end for kubernetes. This is how a user interacts with Kubernetes. - etcd - This is key-value keystore. it is created for managing the cluster and holds all the info about the cluster. Logs are also stored here to make sure there are not conflicts between any masters. - Kubelet - This is the agent that runs on each node in the cluster. This makes sure the containers are running as expected. - container runtime - This is the underlying service used to run containers. a lot of times this is docker, but there are other options as well. - controller - this is the brains. it watches for nodes going down and it makes up decisions to bring up new containers.  - scheduler - used for scheduling work across multiple nodes. looks for newly created containers and assigns them to nodes. kubectl is used as a command line interface for kubernetes. Look at the image below to see how all of these components work together. TODO: insert image here</p> <p>What is a replication controller and a replica set? It allows you to run multiple instances of a container to allow for failure if the container fails in your pod. This will help with high availability. The replication controller will bring up a container when the container fails, and this is true even with single container pods. A replication controller will also help with load balancing and scaling as well.</p> <p>A replication controller is the older technology that is being replaced by replica set.</p> <p>replica sets also have an extra field in the yaml file that is called the selector.</p> <p>What are labels and selectors? Labels are like tags. and you can filter based off labels.</p> <p>What is a kubernetes deployment? A deployment allows you to perform any of the following tasks - deployment of pods or replicasets - upgrade the replicasets or pods seamlessly. - rolling updates. Updating one pod at a time. - undo changes - pause changes - resume changes You will need to create a deployment definition file.</p> <p>Pods are in replicasets, replicasets are part of a deployment.</p> <p>Kubernetes services help us connect other applications together or connects users to our apps. example if you have a front end pod, a back end pod and a database pod. the services help us connect them together. </p> <p>Types of services Node port - A node port service will listen to port on the node and will port forward requests to the pod. cluster ip - the service creates a virtual ip that allows different services to talk with each other load balancer - it allows load balancing on the node.  </p>"},{"location":"Developer%20Training/Kubernetes%20training/kubernetes%20commands/","title":"Kubernetes commands","text":"<p>kubectl run hello-minikube - This will start a pod named hello-minikube</p> <p>kubectl -f pod-definition-yaml-file.yml - this will create a pod based off your yaml file.</p> <p>Here is a cool way to have a file autogenerated for you. kubectl run redis --image=redis123 --dry-run=client -o yaml &gt; redis.yml</p> <p>kubectl cluster-info</p> <p>kubectl get notes</p> <p>kubectl get replicaset kubectl delete replicaset myapp-rs kubectl edit replicaset myapp-rs kubectl replace -f replicaset {yaml file location}</p>"},{"location":"Developer%20Training/Kubernetes%20training/pods/","title":"Pods","text":"<p>Kubernetes does not deploy containers directly on the worker nodes. The containers are encapsulated into a pod. A pod is a single instance of application. a pod is the smallest objects you can create in kubernetes.</p>"},{"location":"Developer%20Training/Kubernetes%20training/pods/#how-to-deploy-a-pod","title":"how to deploy a pod","text":"<p>kubectl run {name of image for pod} --image {name of the image you are trying to install} kubectl run nginx --image=nginx #This will go to docker hub by default and pull ht nginx image down.</p> <p>kubectl get pods # this will show the pods with the default namespace. kubectl describe pod {name of pod} # this will tell you a lot of info about the pod. kubectl describe pod -o wide # another way to find out more info about a pod.</p> <p>Under the ready 1/2, the first number is the number of running pods, the next number is the total number of pods. controlplane ~ \u279c  kubectl get pods  NAME            READY   STATUS             RESTARTS   AGE nginx           1/1     Running            0          8m6s newpods-bgmdp   1/1     Running            0          5m58s newpods-lgwkb   1/1     Running            0          5m58s newpods-tlrw9   1/1     Running            0          5m58s webapp          1/2     ImagePullBackOff   0          3m54s</p>"},{"location":"Developer%20Training/Kubernetes%20training/pods/#yaml-for-kubernetes","title":"Yaml for Kubernetes","text":"<p>There are always 4 top level fields in the deployment yaml file.</p> <ul> <li>apiVersion - This is the api version of kubernetes you are using. Based on the type of container you are using the version could be different. example | Kind | Version | |-|-| | POD | v1 | | Service | v1 | | ReplicaSet | apps/v1 | | Deployment | apps/v1 |</li> <li>kind - This is the type of object you are trying to create.</li> <li>metadata - Data about your pod</li> <li>spec - additional info to kubernetes about the pod you are creating</li> </ul> <p>Example of a yaml file</p> <pre><code>apiVersion: v1                          \nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels: \n    app: myapp\n    type: front-end\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx\n</code></pre>"},{"location":"Developer%20Training/Python%20training/Poetry%20Training/","title":"Poetry Training","text":"<p>pip install poetry Next you need a Toml (Tom's obvious minimal language) file. In this file you will need some basics like  - name  - version - description - authors - license - readme - dependencies</p> <p>You can have this file created for you by using the poetry init file. it will ask you a few questions to help guide you through the creation of the toml file. </p> <p>after this file is created you can use poetry install to create the virtual environment. </p> <p>find out info about the virtual environment by using <code>poetry env info</code>. by default the venv is created somewhere on your pc in a cache folder. this may not be what you want. You can adjust this by changing the poetry config settings. one example would be  <code>poetry config virtualenvs.in-project true</code></p> <p>To now run code in the venv you type <code>poetry shell</code>.</p> <p>to add a package you simply type <code>poetry add request</code>. poetry will update your toml file for you!!! you can do the same with the remove keyword.</p> <p>Private Repository Example https://python-poetry.org/docs/repositories/#private-repository-example</p>"},{"location":"Developer%20Training/Python%20training/Python%20Basics/","title":"Python Basics","text":"<p>You can style you code with different types of standards. Two of the most popular are: - Pep8  - Black</p> <p>The zen of python is the commandments of python. it can be accessed by typing <code> import this </code> in a python interpreter. </p>"},{"location":"Developer%20Training/Python%20training/Python%20Basics/#serialization-and-deserialization-of-data","title":"Serialization and deserialization of data","text":"<p>Serialization and deserialization is the idea of taking data and trasforming so tech can exchange the data better. one example from your day to day life would include a phones call. you talk a person your phone will transform or serialize your spoken words into bits that can then be passed from phone to phone. the other phone will deserialize the data, transforming it from bits back into spoken words. In computer science one example would be take a data sctructure or objects and transforming it into an data that a programming laguage can handle better. example taking a set of JSON data and converting it dictionary and lists for python to use.</p> <p>You can use  <code>  help (module-name) </code> to find out how to use a module.</p> <p>If you want to avoid doing a bunch of escape characters you can us the use a raw string. </p> <p>Parts of a python program Modules - Modules are really just a piece code that you import into your program. everything you import is a module. - modules contain functions, classes, global variables, ect - Why use modules   - Easier readability/maintainability   - Low coupling/high cohesion     - Modules should written in such a way that they do not have any interdependencies.    - Code reusability   - Collaboration</p> <p>Functions - Fuctions are used when you find yourself using the same code over and over again. It is often a good idea to put that code into a function so you dont have to copy paste the code Classes - Classes is a construct that is used in OOP. - This is generally though of a way to define and interact with an object. - Often referred to as a blueprint</p> <p>One important feature of python is that amount of built in libraries and the amount of open source libraries that have been written out in the community. To view a list of all the built-in libraries for python go to https://docs.python.org/3/library</p>"},{"location":"Developer%20Training/Python%20training/Python%20Basics/#list-methods","title":"list methods","text":"Method What it does list.append(element) Add an element to the end of the list list.clear() Removes everything from the list list.copy() Returns a copy of the list. This would be useful when you want to copy the list and you dont just want to create a pointer to the old list. list.count(element) shows the number of the elements with the specified value list.extend(alist) adds the element of a list to the end of the current list list.index() Returns the index number of the fist element with a specified value list.insert(index, element) Adds and element at a specified index value list.pop(index) Removes an element at a specific index position, or if not index position is provided, removes the last item on the list list.remove() Removes a list item with a  specified value list.reverse() Reverses the list order list.sort() sorts the list alphabetically"},{"location":"Developer%20Training/Python%20training/Python%20Basics/#dictionary-methods","title":"Dictionary Methods","text":"Method What it does dict.get(key, set_default_value) If key exists that value will be returned, or the default value of None will be returned. dict.copy() Returns a copy of the dictionary. This would be useful when you want to copy the dictionary and you dont just want to create a pointer to the old dictionary. dict.pop(key) Removes an element at a specific key/value. dict.values() Will return the values of the dictionary. dict.items() Will return the keys and values of the dictionary, used in a for loop."},{"location":"Developer%20Training/Python%20training/Python%20Basics/#sets-notes","title":"Sets notes","text":"<p>What is a set? - It is an unordered grouping of data and is defined by using the curly braces of a dictionary, without the key:value pair. - Sets by default are mutable. - To join two sets your would use the | (pipe), just like a math equation. - You can find the intersections of two sites with the &amp;. - One advantage is that Sets logic can be performed a lot quicker than list logic can be. Example of a set {'192.168.1.1', '10.10.10.10', '172.16.16.1' }</p> <p>A set union looks like this, this will give all the elements and if there is matching data, only one of the same data will show up. set_1_var | set_2_var or you can do the following set_1_var.union(set_2_var)</p> <p>A set intersection will show you only the matching elements in the two sets. set_1_var &amp; set_2_var or you can do the following set_1_var.intersection(set_2_var)</p>"},{"location":"Developer%20Training/Python%20training/Python%20Basics/#function-notes","title":"Function Notes","text":"<p>Basic function rules - Must not start with a number - Must not be a reserved Python word, or a name that has already been used as a function or variable. - Can be any combination of A-Z, a-z, 0-9, underscore or a dash.</p> <p>IMPORTANT NOTE ABOUT FUNCTIONS - Keyword augments will help you a lot. - if you write a basic function without keywords you will have to pass detail in a very specific order.   - Example - def( username, first_name, last_name).    - If you create this as a basic and you change the order of these names when you call the function, your program will not behave how you expect it to. - Here is why you should use keyword arguments. A keyword argument is a name/value pair that you pass to a function. - You might not know how many arguments to expect. Python allows you to use * and ** (often referred to as args and kwargs) to define any number of arguments or keyword arguments. - args is a single argument that you pass in to your function. REMEMBER args is still a positional argument call for your function. *kwargs is a Key value pair that you would pass into your function. - You can define a default value argument in case you have an empty value to send to a function. - </p> <p><code>__name__</code> Specially named variable allowing us to detect whether a module is run as a script or imported into anther module. When you call the module while in a python interpreter, the name of the module will print out. when you call the module from a bash shell, the name __main__ will print out. </p> <p>if you add the following code the your script, when you call the module from a bash shell. you will be able to define a function that you want to have run right away.</p> <p><code>if __name__ == '__main__'; \u00a0\u00a0\u00a0\u00a0module_name()</code></p> <p>if you import this module into a python interpreter, python will know just to import the functions and not call any of them. if you call this module into a bash shell python will call whatever function you define in your if statement. </p> <p>Check out how to use command line arguments. </p> <p>An non empty string will always return true. Watch out for the following. it will return true, because what you are really saying is that if apples is equal to bananas or if peach print true. if \"apples\" == \"bananas\" or \"peach\"     print(\"this is true\") else:     print (\"this is false\")</p> <p>instead do the following.  if \"apples\" in [\"bananas\", \"peach\"]     print(\"this is true\") else:     print (\"this is false\")</p>"},{"location":"Developer%20Training/Python%20training/Python%20Basics/#tryexceptfinally","title":"Try/Except/Finally","text":"<p>try:     your code except (error_you_want_to_except, you could capture more than one if you want) as variable_exception_name:     What you want to happen next     raise custom_exception_you_want_to_raise &lt;&lt;&lt;&lt;&lt;(this keyword, raise is used to re-raise an error. You would use this for capturing custom error messages.) except or_can_capture_another_error_like_this:     do what you want here. finally:     this will run always regardless of if you have an exception or not.</p>"},{"location":"Developer%20Training/Python%20training/Python%20Basics/#important-notes","title":"IMPORTANT NOTES","text":"<p>You should never use broad exception handling. The idea here is that you will expect every error without having to call the the specific error. Although this is an easy way to get your program to run, excepting every error and treating them as the same will make your code very hard to debug and troubleshoot. A use case for using the finally statement is for cleanup of connections that you used in your try or except code. That way you will know that the code in finally statement will always run. </p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/","title":"Python data formats","text":""},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#how-to-open-a-file","title":"How to open a file","text":"<p>** Remember to always close any file that you have opened ** If you would like to have the file close automatically once your are done with it, use the with open context manager.</p> <p>variable_name = open(\"file_name.txt\", \"file_argument\")</p> <p>file arguments include the following - r : open for reading - w : open for writing - x : open for exclusive creation, failing if the file already exists - a : open for writing, appending to the end of the file it is exists - b : open in binary mode - t : open in text mode - + : open for updating (reading and writing)</p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#parsing-data","title":"Parsing Data","text":""},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#comma-separated-values-csv","title":"Comma-Separated Values (CSV)","text":"<p>Python has a built-in CSV module. I highly recommend that you use a CSVDictReader to read data from a CSV File. This will take to top line of your CSV and the current next line down, converting it into a dictionary. converting this data into a dictionary will make you life easier as you get farther in your program.  </p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#javascript-object-notation-json","title":"JavaScript Object Notation (JSON)","text":"<p>JSON is build around a key/value pairing. JSON is used a lot in web services. JSON and Python dictionaries/lists are identical. Python dictionary is a JSON object, Python list is a JSON array. White space does not matter for the Python code to read the data. There are four main functions you will use when working with Python and JSON.   ( The s at the end of the function name means string. ) - load() : This allows you to import native JSON and converts it to a Python dictionary from a file. - loads() : This will import JSON from a string for parsing and manipulating within your program. - dump() : This is used to write JSON data from Python object to a file. You would use this to produce more machine readable code.   - You can set dump ( sort_keys = True, indent = 4) and this will also make your output more readable. - dumps() : This allows you to take JSON dictionary data and convert it into a serialized string for parsing and manipulating with Python. You would use this this to have the output be more human readable.</p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#extensible-markup-language-xml","title":"Extensible Markup Language (XML)","text":"<p>XML works hand and hand in HTML. XML has a tree structure. with the root element being at the very top. All XML works with tags. All data resides in these tags &lt;&gt;, . Understanding XML is important as some protocols/standards work exclusively with XML. Without understanding XML NETCONF with YANG will be difficult to use. XML is one of the more difficult markup languages to learn. You can use xmltodict in Python to help you work with the XML data. You can also use the XML unparse function to make the data easier to read. White space does not matter here.</p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#xml-namespaces","title":"XML Namespaces","text":"<p>XML is very popular and has been used on the internet for many years. You will likely run into an issue were you have two different systems that have the same tag names but they represent different data. This is where XML namespaces and prefixes comes into play. A prefix is an alphabetic character or a string put before the actual tag name followed by a colon.</p> <p>when using XML prefixes you also need to make sure you define namespaces for those prefixes. the name of a namespace is a URI. Namespaces are defined with the xmlns attribute in the starting tag.  router switch router bananas </p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#yaml-aint-markup-language-yaml","title":"YAML Ain't Markup Language (YAML)","text":"<p>YAML is a popular human-readable format for constructing configuration files. Tools like Ansible use YAML files everywhere. White space is very important and your YAML files will break if your white space is off. Use the PyYaml Module in Python to work with YAML files. The two main functions you will use are load() and dump().</p>"},{"location":"Developer%20Training/Python%20training/Python%20data%20formats/#yaml-best-practices","title":"YAML best practices","text":"<ul> <li>indent 2 or 4 white spaces</li> </ul>"},{"location":"Developer%20Training/Python%20training/Python%20dataclass/","title":"Data Classes","text":""},{"location":"Developer%20Training/Python%20training/Python%20dataclass/#what-is-a-dataclass","title":"What is a DataClass?","text":"<p>Data class is a builtin python function that will allow you to make a standard class that will take a decorator of the dataclass module.  </p> <p>Really how it helps is in a normal class that you create you will need to create all the dunder magic methods and create all your attributes for you, saving you time as you create more and more classes. Looking at example code 1, you will me create a class and looking at the example return you will see the output of the class. Now look at example code 2 and using a data class you will see the amount of reduction in code.</p> <p>!!! NOTE !!!  - In these examples I am show the default dataclass. You can tell a data class not the create some of the dunders, if you want. - One limitation( that i have seen so far, maybe I'm wrong) is that you can't create class attributes. </p> <p>Example code 1</p> <pre><code>\nclass NetworkDevice:\n    def __init__(self, device_type, hostname, host_ip_address, host_username, host_password):\n        self.device_type = device_type\n        self.hostname = hostname\n        self.host_ip_address = host_ip_address\n        self.host_username = host_username\n        self.host_password = host_password\n\n    def __repr__(self):\n        return f''' \nNetworkDevice: \n    Device Type: {self.device_type}, \n    Hostname: {self.hostname}, \n    Host IP Address: {self.host_ip_address}, \n    Host username: {self.host_username}, \n    Host Password: {self.host_password}\n'''\n\n    def __eq__(self):\n        pass\n</code></pre> <p>Example code 2</p> <pre><code>from dataclass import dataclass\n\n@dataclass\nclass NetworkDevice:\n    device_type: str\n    host_name: str\n    host_ip_address: str\n    host_username: str\n    host_password: str\n\n</code></pre> <p>Example return 2</p>"},{"location":"Developer%20Training/Python%20training/Python%20dataclass/#gotchas","title":"Gotchas","text":"<p>When you use a data class you do lose some of your abilities to customize. TODO: Show some examples of features you lost by using data classes.</p>"},{"location":"Developer%20Training/Python%20training/Python%20decorators/","title":"Python decorators","text":""},{"location":"Developer%20Training/Python%20training/Python%20decorators/#decorator","title":"Decorator","text":""},{"location":"Developer%20Training/Python%20training/Python%20decorators/#what-is-a-decorator-in-python","title":"What is a decorator in python?","text":"<p>A decorator is a function in python that takes another function as its argument and returns yet another function. Decorators can be extremely useful as they allow the extension of an existing function, without the modification to the original function source code.</p>"},{"location":"Developer%20Training/Python%20training/Python%20decorators/#what-is-a-property-decorator-in-python","title":"What is a property decorator in python?","text":"<p>@property decorator is a built-in decorator in Python which is helpful in defining the properties effortlessly without manually calling the inbuilt function property(). Which is used to return the property attributes of a class from the stated getter, setter and deleter as parameters.</p> <p>Using a property decorator will allow a person using the class to use a method to either get, set or delete an attribute. this is important because you may want to do checks against an attribute to make sure a person is using the attribute properly.</p> <p>In example code 2, allow a user to see the username name, but when they try to access the password I have code that shows them * instead of the actual password.</p> <p>in example code 3 I make sure a user is giving an it for the vlan number and not a string. look at @access_vlan.setter.</p>"},{"location":"Developer%20Training/Python%20training/Python%20decorators/#example-code-1","title":"Example code 1","text":"<p>In this example I will be using the default getter.</p> <pre><code>class NetworkDevice:\n    def __init__(self, host, platform, username, password):\n        self.host = host\n        self.platform = platform\n        self._username = username\n        self._password = password\n\n    @property\n    def username(self):\n        return self._username\n\n    @property\n    def password(self):\n        return self._password\n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20decorators/#example-return-1","title":"Example return 1","text":"<p>In the code above you will see that the attribute is actually set to _username. By using the 'property' decorator you can call the <code>_username</code> as if it were the actual attribute. </p> <pre><code>\n&gt;&gt;&gt; temp_device_1 = NetworkDevice(host='host1.domain.com', platform='cisco_xe', username='admin', password='password123')\n&gt;&gt;&gt; temp_device_2 = NetworkDevice(host='host1.domain.com', platform='juniper_junos', username='admin', password='password123')\n&gt;&gt;&gt; print(temp_device_1.username, temp_device_1.password )\nadmin password123\n&gt;&gt;&gt; print(temp_device_1._username, temp_device_1._password )\nadmin password123\n\n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20decorators/#example-code-2","title":"Example code 2","text":"<p>Here is actually a cool use by using getters and setters.  ```python</p> <p>class NetworkDevice:     def init(self, host, platform, username, password):         self.host = host         self.platform = platform         self.username = username         self._password = password</p> <pre><code>@property\ndef password(self):\n    password_len = len(self._password) + 1\n    return '*' * password_len\n\n@password.setter\ndef password(self, new_password):\n    print(f'You have reset your password')\n    self._password = new_password\n</code></pre> <p>print(temp_device_1.username, temp_device_1.password ) temp_device_1.username, temp_device_1.password = \"new_username\", \"New_Password\" print(temp_device_1.username, temp_device_1.password ) print(f'real password is: {temp_device_1._password} ')</p> <pre><code>\n#### Example return 2\n```python \n\n# Here is the result\nadmin ************\nYou have reset your password\nnew_username *************\nreal password is: New_Password \n\n ```\n\n\n#### Example Code 3\n```python \nclass Interface:\n    def __init__(\n        self,\n        intf_name,\n        intf_mode=\"access\",\n        access_vlan=None,\n        speed=\"1Gbps\",\n        duplex=\"full\",\n    ):\n        self.intf_name = intf_name\n\n        # These two attributes will use the @property.setter constraints defined below\n        self.intf_mode = intf_mode\n        self.access_vlan = access_vlan\n\n        self.speed = speed\n        self.duplex = duplex\n\n    def __str__(self):\n        if self.intf_mode == \"trunk\":\n            return (\n                f\"Interface: {self.intf_name} ({self.speed}/{self.duplex}, \"\n                f\"Mode: {self.intf_mode})\"\n            )\n        else:\n            return (\n                f\"Interface: {self.intf_name} ({self.speed}/{self.duplex}, Mode: {self.intf_mode}, \"\n                f\"Vlan: {self.access_vlan})\"\n            )\n\n    @property\n    def intf_mode(self):\n        return self._intf_mode\n\n    @intf_mode.setter\n    def intf_mode(self, value):\n        if value in (\"access\", \"trunk\"):\n            self._intf_mode = value\n            if value == \"trunk\":\n                self.access_vlan = None\n        else:\n            raise ValueError(f\"Invalid value for intf_mode: {value}\")\n\n    @property #This is creating a method that is the same as the attribute \n    def access_vlan(self):\n        return self._access_vlan\n\n    @access_vlan.setter\n    def access_vlan(self, value):\n        if self.intf_mode == \"access\":\n            if not isinstance(value, int):\n                raise ValueError(\"Access VLAN must be an integer\")\n            self._access_vlan = value\n        elif self.intf_mode == \"trunk\":\n            self._access_vlan = None\n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20inheritance%20and%20composition/","title":"Inheritance vs Composition","text":"<p>Inheritance should be used with a 'is a' relationship. - NetworkDevice as the super class, and a Router 'is a' NetworkDevice. Composition should be used with a 'has a' relationship. - A Router class 'has a' NetworkInterface class.</p>"},{"location":"Developer%20Training/Python%20training/Python%20inheritance%20and%20composition/#inheritance","title":"Inheritance","text":""},{"location":"Developer%20Training/Python%20training/Python%20inheritance%20and%20composition/#what-is-inheritance","title":"What is inheritance?","text":"<p>Inheritance is the idea of a class that can use a higher level classes methods and attributes. Example I have a <code>NetworkDevice</code> class that has a <code>ip_address</code> attribute. I create a <code>Router</code> class and I dont want to create another <code>ip_address</code> attribute. I can just inherit the <code>NetworkDevice</code> class and when someone create a <code>Router</code> object, they will need to put in a <code>ip_address</code> attribute. </p>"},{"location":"Developer%20Training/Python%20training/Python%20inheritance%20and%20composition/#gotchas","title":"Gotchas","text":"<p>Here is one potential problem you need to be aware of and look out for. In example code 1 below, I created a <code>NetworkDevice</code> class, and a <code>Router</code> class. The <code>Router</code> class inherits from the <code>NetworkDevice</code> class. I did not code the <code>__repr__</code> very well and when I went to print the temp_router, You see the repr is saying the router is a <code>NetworkDevice</code> object.</p> <p>A better way to code the <code>NetworkDevice</code> class is shown in example NEED TODO:</p> <p>Example Code 1</p> <pre><code>class NetworkDevice:\n    def __init__(self, hostname, host_ip_address, host_username, host_password ):\n        self.hostname = hostname\n        self.host_ip_address = host_ip_address\n        self.host_username = host_username\n        self.host_password = host_password\n\n    def __repr__(self):\n        return f''' \n NetworkDevice: \n     Hostname: {self.hostname}\n     Host IP Address: {self.host_ip_address}\n     Host Username: {self.host_username}\n     Host Password: {self.host_password}\n'''\n\nclass Router(NetworkDevice):\n    pass\n\ntemp_router = Router(\n    hostname=\"router1\", \n    host_ip_address= \"10.1.1.1\", \n    host_username=\"router_admin\", \n    host_password= \"router_password\")\n\nprint(temp_router)\n</code></pre> <p>Example output 1</p> <pre><code>\n NetworkDevice: \n     Hostname: router1\n     Host IP Address: 10.1.1.1\n     Host Username: router_admin\n     Host Password: router_password\n</code></pre> <p>Example Code 2</p> <pre><code>class NetworkDevice:\n    def __init__(self, hostname, host_ip_address, host_username, host_password ):\n        self.hostname = hostname\n        self.host_ip_address = host_ip_address\n        self.host_username = host_username\n        self.host_password = host_password\n\n    def __repr__(self):\n        return f''' \n NetworkDevice: \n     Hostname: {self.hostname}\n     Host IP Address: {self.host_ip_address}\n     Host Username: {self.host_username}\n     Host Password: {self.host_password}\n'''\n\nclass Router(NetworkDevice):\n    def __repr__(self):\n        return f''' \n Router: \n     Hostname: {self.hostname}\n     Host IP Address: {self.host_ip_address}\n     Host Username: {self.host_username}\n     Host Password: {self.host_password}\n    pass\n\ntemp_router = Router(\n    hostname=\"router1\", \n    host_ip_address= \"10.1.1.1\", \n    host_username=\"router_admin\", \n    host_password= \"router_password\")\n\nprint(temp_router)\n</code></pre> <p>Example output 2</p> <pre><code>\n Router: \n     Hostname: router1\n     Host IP Address: 10.1.1.1\n     Host Username: router_admin\n     Host Password: router_password\n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20inheritance%20and%20composition/#composition","title":"Composition","text":""},{"location":"Developer%20Training/Python%20training/Python%20intermediate/","title":"Python intermediate","text":""},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#error-handling-in-python","title":"Error Handling in Python","text":"<p>I need to find better documentation than the book</p>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#classes","title":"Classes","text":"<p>What is an object? A object is two things - Attributes   - data about a object   - Can have private or public attributes - Methods   - What a object can really do   - Can have private or public methods   - Functions created inside a class are called methods.</p> <p>NOTE extra learning for classes To learn more about classes, methods, and inheritance, you can refer to the Python documentation. https://docs.python.org/3/tutorial/classes.html if you would to to find out more about a module or the methods use the following commands. - help(module) or help(module.function) - dir(module)</p>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#what-is-self","title":"What is self?","text":"<p>when you create a new object python will call a <code>__new__</code> method. That will create an object in memory. Then python will call the <code>__init__</code> method of the object.</p>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#attributes","title":"Attributes","text":"<p>Class Attributes - All instances of a object of the class type will receive this attribute - When using a class attribute, you will need to be careful how you use it.    - if you call <code>class_name.class_attribute</code> and update it, this way will update the class attribute. if you call <code>self.class_attribute</code> and update it, you are actually creating a new class attribute.   example</p> <pre><code>class Person(): \n    person_type = \"Spam\"\n\n    def __init__(self):\n      person_type = \"Homosapien\" \n\nadam = Person() \nprint(adam.person_type)\n\noutput &gt;&gt; Homosapien\n\nprint(Person.person_type)\noutput &gt;&gt; Spam\n</code></pre> <p>Instance Attributes This uses an initializer. This is unique to each object</p> <pre><code>class Person:\n  person_type = \"Homosapien\" #this is a class attribute \n  def __init__(self, height, weight, sex):\n        self.height=height #&lt;&lt;&lt;&lt; instance attribute\n        self.weight=weight #&lt;&lt;&lt;&lt; instance attribute\n        self.sex=sex       #&lt;&lt;&lt;&lt; instance attribute\n</code></pre> <p>What is a magic method?</p> <p>A magic method is a special method that you can define to add 'magic' to your classes. you can add built in methods to you classes example  </p> <p>error with no length method  </p> <pre><code>&gt;&gt;&gt; class Friends:\n...     members=['Ross', \"Phoebe\", 'Chandler', 'Joey', 'Monica', \"Rachel\"]\n...   \n&gt;&gt;&gt; my_list_friends = Friends()  \n&gt;&gt;&gt; len(my_list_friends)  \nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: object of type 'Friends' has no len()  \n</code></pre> <p>no error with length method  </p> <pre><code>&gt;&gt;&gt; class Friends:  \n...     members=['Ross', \"Phoebe\",   'Chandler', 'Joey', 'Monica', \"Rachel\"]  \n...     def __len__(self):  \n...         return len(self.members)  \n...\n\n&gt;&gt;&gt; my_list_friends = Friends()  \n&gt;&gt;&gt; len(my_list_friends)  \n6\n'''\n\nHere is another example. but this time I am trying to see if a name is in the list of friends  \n``` python\n&gt;&gt;&gt; class Friends:  \n...     members=['Ross', \"Phoebe\", 'Chandler', 'Joey', 'Monica', \"Rachel\"]  \n...     def __len__(self):  \n...         return len(self.members)  \n...   \n&gt;&gt;&gt; if 'adam' in my_list_friends:  \n...     print ('adam is in the list')  \n... else:  \n...     print('adam is not a friend. :( ')  \n...   \nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: argument of type 'Friends' is not iterable  \n&gt;&gt;&gt;   \nKeyboardInterrupt  \n&gt;&gt;&gt;   \n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#here-is-a-version-of-the-check-to-see-if-adam-is-a-friend","title":"Here is a version of the check to see if adam is a friend.","text":"<pre><code>&gt;&gt;&gt; class Friends:  \n...     members=['Ross', \"Phoebe\", 'Chandler', 'Joey', 'Monica', \"Rachel\"]  \n...     def __len__(self):  \n...         return len(self.members)  \n...     def __contains__(self, friend):  \n...         return friend in self.members  \n...   \n&gt;&gt;&gt; if 'adam' in my_list_friends:  \n...     print ('adam is in the list')  \n... else:  \n...     print('adam is not a friend. :( ')  \n...   \nadam is not a friend. :( \n</code></pre> <p>You can also do a string magic method and make your class look even prettier.</p> <pre><code>class Person:\n  person_type = \"Homosapien\" #this is a class variable \n  def __init__(self, height, weight, sex):\n        self.height=height   #&lt;&lt;&lt;&lt; instance attribute\n        self.weight=weight   #&lt;&lt;&lt;&lt; instance attribute\n        self.sex=sex         #&lt;&lt;&lt;&lt; instance attribute\n  def lb_to_kg(self):\n      weight_in_kg = self.weight/2.205\n      print(weight_in_kg)\n  def dominate_hand(self, hand):\n        if hand in [\"right\", \"Right\", \"r\", \"R\" ]:\n          print(\"You are right handed\")\n        elif hand in [\"left\", \"Left\", \"l\", \"L\"]:\n          print(\"You are left handed\")\n        else:\n          print(\"You are no handed?\")\n  def __str__(self):\n        return f\"I am a person, I am { self.height } ft tall, I weigh {self.weight} lbs. I am also a {self.sex} \"\n\n&gt;&gt;&gt; adam=Person(6,250,\"Male\")  \n&gt;&gt;&gt; print(adam)  \nI am a person, I am 6 ft tall, I weigh 250 lbs. I am also a Male   \n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#private-membership","title":"Private Membership","text":"<p>With python you can only say that a attribute or method is private. you can't really block the use of the private member from public use. You would put an underscore in front of a private member to signify that the user of your app should not use this member. That this member should only be used for inside the app</p>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#static-methods","title":"Static Methods","text":"<p>A static method can not change the instance or the class. It acts more like a function. There are some cases where you would want to use a static method, and that would be more because you are using inheritance in your classes. You could create that same function outside of you class, its really just up to the developer. </p>"},{"location":"Developer%20Training/Python%20training/Python%20intermediate/#class-methods","title":"Class Methods","text":"<p>Best practices - Use uppercase letters for a class name - Use self as the first positional argument. You could use others besides self, but don't do it. just use self.</p> <p>Environment variables within python - You can create .env file and add your environmental variables there instead of putting them in a .bash file or putting them in your OS specific env files. You will need to pip install and import a module call \"dotenv\"</p>"},{"location":"Developer%20Training/Python%20training/Python%20logging/","title":"Python logging","text":""},{"location":"Developer%20Training/Python%20training/Python%20logging/#logging","title":"Logging","text":"<p>logging module built into python. No need to install anything special.</p> <p>Link to the python documentation. https://docs.python.org/3/library/logging.html</p>"},{"location":"Developer%20Training/Python%20training/Python%20logging/#why-use-logging-vs-print","title":"Why use logging vs print?","text":"<p>Logging will allow you to capture additional data about the running of your code. It will give you flexibility as to how you capture your logs. Print only allow very basic capturing of your logging.</p>"},{"location":"Developer%20Training/Python%20training/Python%20logging/#logging-levels","title":"logging levels","text":"Level Numeric value Description CRITICAL 50 A serious error, indicating that the program itself may be unable to continue running. ERROR 40 Due to a more serious problem, the software has not been able to perform some function. WARNING 30 An indication that something unexpected happened, or indicative of some problem in the near future. INFO 20 Confirmation that things are working as expected DEBUG 10 Detailed information, typically of interest only when diagnosing problems. When this is used it works a lot like the print statement and displays basic data to the screen. NONSET 0"},{"location":"Developer%20Training/Python%20training/Python%20logging/#how-to-set-up-logging","title":"How to set up logging","text":"<p>Here is a very VERY basic logging script. </p> <p>The following is showing that you want to see warning levels and higher. When main is run you would only see critical, error and warning levels.</p> <p>When using this basic config in your script like this, you will be using that is called the root logger. Below is a section that will explain a root logger vs import logger and why this is important. </p> <pre><code>import logging\n\ndef main() -&gt; None:\n    logging.basicConfig(level=logging.WARNING)\n\n    logging.debug(\"This is a debug message\")\n    logging.info(\"This is a info message\")\n    logging.warning(\"This is a warning message\")\n    logging.error(\"This is a error message\")\n    logging.critical(\"This is a critical message\")\n</code></pre> <p>Example of the output</p> <pre><code>\n&gt;&gt;&gt; main()\nWARNING:root:This is a warning message\nERROR:root:This is a error message\nCRITICAL:root:This is a critical message\n</code></pre> <p>Here is an example of the same code but I have added some formatting. Format keyword is used to show what is displayed to the screen or the output file. The datefmt keyword is used to configure the (asctime) and show what time you want to show up. By default, the logging is written to the console. if you would like to to write the logging to a file you only need to add a filename keyword and the name of the log you are creating. NOTE when adding filename logging keyword to the config all of the output is sent to the logging file. logging will add to the existing log file, logging does not overwrite it by default. </p> <pre><code>import logging\n\ndef main() -&gt; None:\n    logging.basicConfig(\n        level=logging.WARNING,\n        format=\"%(asctime)s %(levelname)s %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n        filename=\"logging_training.log\",\n        )\n\n    logging.debug(\"This is a debug message\")\n    logging.info(\"This is a info message\")\n    logging.warning(\"This is a warning message\")\n    logging.error(\"This is a error message\")\n    logging.critical(\"This is a critical message\")\n</code></pre> <p>Here is the output of the formatted output. </p> <pre><code>2023-09-19 15:05:14 WARNING This is a warning message\n2023-09-19 15:05:14 ERROR This is a error message\n2023-09-19 15:05:14 CRITICAL This is a critical message\n</code></pre>"},{"location":"Developer%20Training/Python%20training/Python%20logging/#root-logger-vs-imported-logger","title":"Root logger vs imported logger","text":"<p>TODO: I need to learn this.</p>"},{"location":"Developer%20Training/Python%20training/Python%20logging/#more-advanced-logging","title":"More advanced logging","text":"<p>if you only need the most basic level of logging and you only really plan on using these logs for yourself using the basicConfig logger makes the most sense. If you would like to share this logger, or user different logging customizations for different parts of your code, or many other reasons. The better solution is to use a logger.</p>"},{"location":"Developer%20Training/Python%20training/Python%20logging/#breaking-down-more-advanced-logging","title":"Breaking down more advanced logging","text":"<p>You have a logger. This is the configuration of how your logging will work.</p> <p>You have handlers. - Handlers are what you do with your logs. - Handler types   - Stream handler - puts logs out to screen.    - File handler - puts logs out to a specific file.</p> <p>If you default to the root logging and you decide to import a different module that also has a root logger, the root logger of the imported class will actually do the logging and the logger you have in your main code down below will not be called, because you already have a root logger called. Example of best practice code</p> <p>using the <code>__name__</code> will pass the name of the module you are running into the logger, this will replace the word root in the logger.</p> <pre><code>import logging\nlogger = logging.getLogger(__name__)\n\n#You would use this next part if you want to customize your logger a bit more. This will allow you to change the root logger info.\nlogger.setLevel(logging.INFO)\nformatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s:%(message)s')\nfile_handler = logging.FileHandler('runbook_logging/testlog2.log')\nfile_handler.setFormatter(formatter)\n\nlogger.addHandler(file_handler)\n\n</code></pre> <p>You can also do a logging.exception inside a try/except block to log the traceback errors.</p> <p>If you want this logging to show up on your console window you can use a stream Handler.</p>"},{"location":"Developer%20Training/Python%20training/Python%20logging/#other","title":"Other","text":"<p>if you call a method without the parentheses, the code will call a memory reference to the method. </p>"},{"location":"Developer%20Training/Python%20training/Python%20regex/","title":"Python regex","text":"<p>import re</p> <p>This will search re.search(r\"regular_expression_pattern\",  what_you_are_searching_through)</p> <p>This will show you what you matched re.search(r\"regular_expression_pattern\",  what_you_are_searching_through).group(0)</p> <p>You can set a name of a match to a dictionary.</p> <p>match = re.search(r\"some_pattern (?Psome_pattern_you_want_to_save)\") match.groupdict() <p>You can also use a flag that will allow you to use the ^ and $ on every line. the default behavior would start the ^ at the beginning of your file and the $ at the end of your file.  </p> <p>re.search(r\"regular_expression_pattern\",  what_you_are_searching_through, flags=re.M)</p> <p>the * symbols will not go past a new line character. To fix this issue you would set your flags=re.DOTALL</p> <p>Some other methods you might want to use - re.split() - re.sub() - re.findall()</p> <p>Greedy vs non-greedy By default python regular expressions are greedy, meaning they will match the longest string possible. The non-greedy (also know as lazy) will match on the shortest string possible. The non-greedy version is followed by a question mark. </p>"},{"location":"Networking/Cumulus%20Linus/","title":"Cumulus Linus","text":""},{"location":"Networking/Cumulus%20Linus/#what-is-cumulus-linux","title":"What is Cumulus Linux?","text":"<p>It is an Network operating system that is written on debian linux.</p> <p>This part is actually Nvidia/Mellanox. What is infiniband? computer networking communication standard. used in high.performance computing. it has very hight throughput and very low latency. its used to connect compute resources, storage, server communications. Infiniband uses a technology that can utilize all layers of the OSI to move data as fast as possible. Equipment needed for infiniband - Switches - Subnet manager manages all network activity - Network adapters for the hosts - gateway   - This is used to allow infiniband devices and ethernet devices to talk to each other  - infiniband router   - used to allow infiniband networks to talk to one another Key features of infiniband - simplified management  - managed but the subnet manager  - every subnet has its own subnet manager master  - the second subnet manager is a standby  - this is used for control plane traffic - high bandwidth  - started at 10 gb  - currently is 400 gbps - cpu offloads   - hardware based transfer protocol   - the application sends it data to the hardware level and is able to skip the kernel. this means the less cycles are hitting the cpu   - RDMA(Remote direct memory access) NEED TO LOOK AT MORE   - The gpus also have this same technology - ultra low latency - network scale out   - You can deploy up to 48000 nodes on a single subnet     - What is a node?     - How big is a subnet?     - ip addressing? - OQS - fabric resiliency   - Self healing recovery     - if a link failure happens the recovery time take 1 Millisecond - optimal load-balancing   - adaptive routing is an option for load balancing. ( its like ecmp)    - enabled on the hardware   - controlled by adaptive routing manager   - the queue manager watches all of its links   - the queue manager will send out data based on the data it has gathered - sharp (scalable hierarchical aggregation and reduction protocol) MPI super performance   - Sharp helps reduce the data traversing the network - Variety of supported topologies   - fat tree   - torus   - dragonfly+   - hypercube   - hyperX infiniband architecture  - Applications can talk to each other without going though the OS - layers   - upper layer     - describes the how Applications use the Infiniband system        - some protocols used by the uppper layer include         - MPI - Message passing interface         - NCCL - NVIDIA collections communication library         - iSER - RDMA storage protocols         - IPoIB - ip over infiniband   - Transport layer     - A tunnel is created between two apps   - network layer   - Link layer     - local ID or LID      - flow control   physical layer </p>"},{"location":"Networking/Data%20Center%20Notes/","title":"Data Center Notes","text":"<p>What is the Hierarchical design? - Used in campus networks mainly. - Relies on north/south traffic. - Must use the core often - Lots of spanning tree/Trunks/Port-channels - if you move from one area to another. your device will need a new ip address. - Or you can send the Layer-2 vlans across the access layer. but this will increase the broadcast traffic as well as the layer 2 failure domain size. And this will only work at the distribution layers because the core is routed network. - This design works at the campus because DHCP can hand out new ip address. but this will not work in the DC where most hosts have static ip address. </p> <p>What is Spine/leaf? - There are only two levels. - Every leaf switch connects to every spine. - A host is at most 2 switch hops away to a destination - Every connection between a leaf and spine must have a ip address. - Spine switches are never connected to each other, and leaf switches are never connected to each other.    - This is true in most cases except for VPC. In this case two switches would have a Layer 2 peer link and a layer 3 keep alive. And these links are used for VPC traffic only - This design will allow for east west traffic. </p>"},{"location":"Networking/EVPN/","title":"EVPN","text":"<p>Why EVPN? One reason is moving VMs into different segments of the data center without changing their IP address. Vmotion Industry standard</p> <p>What is needed to build an EVPN Network? - Topology (leaf/Spine) - Underlay   - OSPF - IP unnumbered   - ISIS - IP unnumbered   - iBGP - IP numbered   - eBGP - IP numbered - Overlay   - MP-BGP     - evpn address family is the standard     - What will we be learning in MP-BGP       - Mac address         - You are effectively routing MAC address around       - IP host/32       - IP network     - LOTS OF BGP PEERING. Peer groups will be your friend here.     - if you choose eBGP. one idea is to have your spines be the same AS. and maybe even segment your leaves into groups of the same AS. - You should use automation when deploying EVPN. - NOTES   - Although this is not required its kind of a industry standard     - Loopback 0 - Overlay Routing protocol       - Every device will get a loopback 0 for routing      - Loopback 1 - VTEP Address       - Generally Loopback 1 is only on the leaves where the VTEP exists.</p> <p>VRF - Logically separate routing table. - gives you a way to separate data on a device. You can also use the same ip address on device.  - If you want the VRFs to talk. they must meet and exchange routes - normally i see that each vrf has its own separate link. but what happens when you have only 1 link between 2 devices?   - Route Distinguishers and Route Targets     - Route Distinguishers       - This will allow you to tell if the difference between two routes that are the same in the same route table       - This makes each route unique in the routing table. that is all it does.       - This may never match between routes and sites. and this works well because it one extra level to help you troubleshoot an issue. a lot of time the loopback of the device is used as the route distinguisher     - Route Targets       - is it metadata,        - You would use an import and export statement.       - you export your route with a tag. then on the the other device you would import that tag and drop that route into the vrf that you want to.       - This must match on every device for the VRF you care about Three different VRF you will use on every device - Default   - this is down with the normal command <code>ip vrf</code> - Mac VRF (L2VNI)   - used for Mac address   - This is done as a vlan on the switch   - in EVPN if you are using physical switches every VNI must have a Vlan tied to it. every vlan has a VNI tied to it. 1 to 1 mapping   - the data is like a normal mac table. it is also called a stretched vlan.   - It is just like a bridging table.   - Type 2 route - going to have a RD and a RT    - All of this is done at the control plane. meaning that each packet knows where to go, and no cpu needs wasted at the data plane layer.    - normally you would have to send a frame with a vlan tag. and that tag is stripped off at the data layer. costing cpu and slowing down the process because of the extra step.   - This will not take up any CAM to TCAM space   - Spanning tree will still be running but its only to protect you if you decide to plug a switch into a switch. Not for actual data.</p>"},{"location":"Networking/Network%20Programmability/","title":"Network Programmability","text":""},{"location":"Networking/Network%20Programmability/#sdn-and-ibn","title":"SDN and IBN","text":"<p>Software defined networking and Intent based networking SDN is a building block of IBN</p>"},{"location":"Networking/Network%20Programmability/#sdn","title":"SDN","text":"<p>SDN characteristics and components are as follows: - Network devices - These devices talk to the SDN controller on the controllers southbound interfaces - SDN controller - Brains of SDN, communicates with network devices, applications and services using APIs - Southbound interface - The interface the SDN talks to the down stream devices.   - Southbound controller protocols     - OpenFlow     - NETCONF     - RESTCONF     - OpFlex     - REST     - SNMP     - Vendor-specific protocols - Northbound interface - The interface that talks with applications and services - Network management applications and services</p> <p>SDN Benefits - Centralized Provisioning - Network security - Faster Deployments - Programmable</p>"},{"location":"Networking/Network%20Programmability/#ibn","title":"IBN","text":"<p>Intent enables the express of both business purpose and network context through abstractions, which are translated to achieve the desired outcome for network management.</p> <p>The three foundational elements of IBN are as follows: - Translation - What to accomplish, not how. - Activation - This part deploys the policies from the translation element. - Assurance - This part verifies the continue operations and the activation happened properly.</p> <p>IBN Characteristics - Translation and validation - Automation - State awareness - Assurance and optimization</p> <p>IBN Benefits - Reduced complexity - Simplifies deployment - Strengthens security - Improves agility - Eliminates repetition</p>"},{"location":"Networking/VxLAN/","title":"VxLAN","text":"<p>What is VxLan? - it it helps reducing the need for Spanning tree, trucking - It allows you to put a Layer 2 network overlay with a layer 3 underlay - Standard based - RFC XXX  </p> <p>Vlan  - id is 12 bits long - which allows for 4095 vlans - Concept if you have customers in your data center   - if you gave each customer 8 vlans, you only have room for 511 customers</p> <p>VxLan - VNI = VxLAN Network Identifier - A VNI is a bridge domain - Traffic is encapsulated with UDP and IP  - VNI work just like Vlans. if you want to go between VNIs you will need a router. - Changes to the Underlay does not impact the Overlay. as long as there is ip connectivity. - id is 24 bits long - 16,777,216 segments - VNI can be created as a    - L2VNI     - used for bridging     - Used when traffic is located in the same lan segment.   - L3VNI     - Used for Routing     - When traffic need to leave a L2VNI     - Optional ( but needed if you want to route on the local switch)     - All VTEPs need to learn about all L3VNIs       - This is to support a feature called Anycast Gateway       - Each switch acts as a default gateway for the hosts in that VNI       - Every switch will have the same IP address and the same virtual MAC address.       - No need for timers like HSRP or other FHRP.       - All hosts can have a same default gateway. doesnt matter what switch they are connected to.     - Mulitentacny        - L3VNI are attached to a VRF       - Many VNIs can be associated with a Customer or Tenant        - Routes and route tables will be kept separate by using Route distinguisher and route targets.</p> <p>VTEPs - Basics   - Is a special kind of interface   - VTEPs connects the overlay to the underlay   - VTEP has a ip address in the underlay and 1 or more VNIs   - traffic between a source and destination VTEP create a stateless tunnel. the tunnel is formed long enough to pass the VxLan frame in the tunnel   - When traffic comes to a VTEP, the VTEP will encapsulate the traffic and sent that traffic to the remote VTEP to be decapsulated.   - The VTEPS are on the leaf switches.   - VxLAN tunnels are created on leaf switches.   - If you use BGP Spine switches can become Route-Reflectors. - Address learning   - Data Plane Learning (This is the older Method)     - flooding learning     - ARP      - No build in support for routing     - if you want to go between VNIs you need to have an external router   - Control Plane Learning (Newer way of address learning)     - More efficent     - The switches learn about the mac address before they are needed.     - Switches peer with each other.     - This uses the EVPN address family   - Traffic types     - Unicast traffic     - BUM Traffic (Traffic that goes to more then one destination)       - BUM traffic Type         - Broadcast         - Unknown Unicast         - Multicast       - How to handle BUM traffic         - Multicast           - Each VNI is matched to a single Multicast group           - Each Multicast group may match to 1 or more VNI           - When a VTEP comes online, the VTEP will use IGMP to join the multicast group that it uses.           - When VTEP needs to sent BUM Traffic, the VTEP will only to the relevant multicast group.           - Could be complicated, based on your multicast environment.          - Headend replication            - Must use BGP with EVPN            - When BUM traffic arrive, the VTEP will send multiple unicast traffic packets to the other VTEP that support that VNI           - Does not scale as well, but is much simpler to implement.            - One recommendation is 20 VTEPs or less ( 20 leaf nodes)</p> <p>How does a Host talk to another host? - all Switches must run iBGP - A full mesh must be created or route reflectors must be used. - When a switch is added that is running a VTEP. That switch will learn where all of your other VTEPs are. - When VTEPs are added through BGP. Those VTEPs are added to a white list. All other VTEPs are untrusted. - BGP authentication would be good idea to eliminate rogue peers.  - host MAC Address are added to the local BGP process. The host is discovered when they start up. The host MAC address is shared with all BGP peers. When a host sends another host data, the switch looks up the other host with BGP. - You will be using ARP surpression. but the host will still need to use ARP. but the ARP request will go the Switch. the switch will know the MAC address of the remote host and end up sending the ARP right back without flooding the other switches.</p> <p>Encapsulation of a data using VxLAN Ethernet|IP|UDP|VxLAN|frame</p> <p>VxLAN header -  Total of 64 Bits reserved - 8-bits VNI - 24-bits: The VxLAN ID Reserved - 24-Bits Flags - 8-bit; Bit-3 shows VNI is valid</p> <p>Things to know - UDP destination port is 4789  - Know that you will need to have Jumbo frames enabled for best results - ECMP (Equal-cost Multipath) routing will help significantly with this strategy.  - if your fabric starts to grow too large, you can break up the design into more spine/leaves. At this point you would add a Super-spine. (Not used very often)</p> <p>What about Routers/Firewalls/Load Balancers/ETC? - This functionality is added to the Leaf layer. - When routers/Firewalls are added to a leaf, the leaf becomes a boarder leaf. - Boarder leaf switches represent connectivity to and from the fabric.</p> <p>Thoughts to help me understand - it seems like frame that is already constructed goes to the VTEP. The VTEP encapsulated the frame adds VxLAN tag( for lack of a better word). once the frame has the new VxLAN header, the frame brought back up to layer 4, and starts again.</p> <p>!!!! Not sure where to put this yet. but Need to take the notes</p>"},{"location":"System%20Admin/Linus%20Notes/","title":"Basic notes","text":""},{"location":"System%20Admin/Linus%20Notes/#wildcards","title":"Wildcards","text":"Wildcards meaning * Matches any characters ? Matches any single characters [characters] Match any character that is a member of the set characters [!characters] Match any character that is a not member of the set characters [[class]] Match any character that is a member of the specified class Class Meaning [:alnum] Matches any alphanumeric character [:alpha] Matches any alphabetic character [:digit] Matches any numeral [:lower] Matches any lowercase letter [:upper] Matches any uppercase letter"},{"location":"System%20Admin/Linus%20Notes/#linux-file-notes","title":"Linux file notes","text":"Directory Purpose / root directory /bin Contains binaries(programs) that must be present for system startup /boot Contains linux kernel. initializes RAM disk image and boot loader /dev Special directory that contain device nodes. \"Everything is a file in linux. Here is where the kernel maintains a list of all the devices it understands /etc This directory contains all the system-wide configuration files. /home Each user is given a directory in /home. It is like the user folder in windows /lib Contains shared library files used by the core system programs.like DLLs in windows /lost + found It is used in the case of a partial recovery from a file system corruption event. Unless something bad happens this folder will remain empty /media On modern linux systems, this directory will contain the mount points for removable media such as USB drives. /mnt On older linux systems this directory contains the mount points for devices that have been mounted manually. /opt Used to install \"optional\" software. Mainly used to hold commercial software products /proc This directory is special. It's not a real file system in the sense of files stored on your hard drive. It's a virtual file system maintained by the kernel. The files contain peepholes into the kernel itself /root Home directory for the root user /sbin System Binaries. Needed for the system to run. Accessed only by a super user. /tmp used for temp storage of devices /usr It contains all program and support files used by a regular user. /var This directory is used often and hold data about the system. /var/log This is where system logs are stored."},{"location":"System%20Admin/Linus%20Notes/#basic-linux-commands","title":"Basic linux commands","text":"Command Name Description Extra vars pwd Present working directory Shows the directory that you are currently in cd {path name} Change directory change to a different directory ls {path name or argument} List directory contents less opposite of more allows you to scroll up and down in a test file (useful) mv cp mkdir -p (adds recursive directories) ln original-file-or-directory new-link link Creates a link Hard be default -s (used to create a symbolic link) rm -r (means recursive), -f (means force), -rf (recursive and force)"},{"location":"System%20Admin/Linus%20Notes/#tech-support-commands","title":"Tech support commands","text":"Command Name Description Extra vars systemctl {start stop reboot ect} (service) hostnamectl which (application name) apt show (application name) ps ps used to see the top running processes -ef(to see top processes) whoami ip link ip link tells some data about a link ip addr ip address This will tell you your ip address"},{"location":"System%20Admin/Linus%20Notes/#tcpdump","title":"tcpdump","text":"<p>tcpdump is a tool that allows you to sniff traffic from a devices interfaces. example of command below tcpdump -i {interface name} -v src {source ip} and dst {destination ip}</p> <p>tcpdump flag types |Flag| What it does| |-|-| |host| Specify the any traffic to or from a ipaddress or DNS name.| |net| Network to watch | |-v| verbose mode|  |-w {filename.pcap}| write out a file| </p> capture filter What it does and, or, not if combining filters you must use these commands. src Specify any traffic sourced from an IP address or DNS name. dst Specify any traffic destined  from an IP address or DNS name. tcp tcp protocol capture udp udp protocol capture port This is to watch traffic that is using a range of ports or a individual port."},{"location":"System%20Admin/Linus%20Notes/#wget","title":"Wget","text":"<p>Wget will allow us to download files from the internet to the server.</p> <p>Example below wget {download url} |Flags | What the flag does| |-|-| | -O {filename} | This will allow you to change the name of the file.| | -P {custom path}| This will allow you to change the location where the file will download to.| | -c | This will allow continue a download that interrupted for some reason.| | -i | This will allow you to use an input file. incase you wanted to download a bunch of files at once that you call out in a file.|</p>"},{"location":"System%20Admin/Linus%20Notes/#curl","title":"cURL","text":"<p>Curl will allow you to do a api call to web server.</p> <p>curl url</p>"},{"location":"System%20Admin/Linus%20Notes/#link-types","title":"link types","text":"<p>Symbolic links - This is really like a shortcut on windows - It is a pointer to the file - If you delete the original file, the symbolic link will become useless - This is the more modern way of creating links - Different iNode numbers Hard links - A different name for the same file - same file size - Same iNode numbers - Deleting the original file, will still allow hard links to be operational Here is a picture of the two links </p> <p>What is a Daemon? - A type of program on unix-like operating systems that run unobtrusively in the background.  - sshd is a good example. sshd is a program hat is always running, ready to accept or send ssh connections.</p>"},{"location":"System%20Admin/Linus%20Notes/#notes","title":"Notes","text":"<p>log files are stored under /var/log - if you want to learn about less, more, grep, ect. log files are good for learning about the basics</p>"},{"location":"System%20Admin/Linux/","title":"Linux","text":""},{"location":"System%20Admin/Linux/#bash","title":"BASH","text":"<p>BASH stands for Bourne Again Shell. BASH is one of the most popular shells available today.  Bash supports features such as piping. variables, evaluations of conditions and iterations.</p> <p>Quick linux commands | Command | Command name | Command description | Important Flags | |---------|--------------|---------------------|-------| | man { command name} | Manual | This command will provide information about another command | cat {file name} | Concatenate |  This command will show the output of a file right on your screen. The command can also be used for outputting test to a new file. | cd  {location to move to} | Change dictatory | This command will allow you to change your current dictatory | pwd | Present working dictatory | This command will print out your current working dictatory to your screen. This can be helpful for scripting. | ls |  List directory contents | This command will list out the contents of a directory | -a (Shows hidden files), -l (show file permissions) | mkdir {new directory name} | Make directory | This is used to a new directory | cp {copy from} {copy to} | Copy | This will copy a file or a directory | -r (copy a folder and all the files in the folder) | mv {move from} {move to} | Move | This will move one files from a directory to a different directory. You would also use this to rename a file. | rm {file name} | Remove | This will remove a file or a folder. | -r (removes directories and their contents), -f (this will force removal of files and never prompt) | touch {File name} | Touch | This will create a file or update the modified date of a file.</p>"},{"location":"System%20Admin/Linux/#environment-variables","title":"Environment Variables","text":"<p>What is an environment variable? - Its really just a variable that you set for you OS. This can be set for anything. You can setup a folder as a variable, you can set up an API key as a variable, you can set up a number, ect.  - You would do this in programming to set up a folder location mapped to your variable, that way you can call this variable in your OS to help you find folders better. - Variables are only loaded at the start of your terminal session.</p> <p>Add your environment variable to your .bashrc either by - nano into your .bashrc - or $ echo \"export PATH=$PATH:/{LOCATION NAME}\" &gt;&gt; .bashrc</p> <p>then run source ~/.bashrc</p>"},{"location":"System%20Admin/regex%20training/","title":"Regex training","text":""},{"location":"System%20Admin/regex%20training/#what-is-the-purpose-of-regular-epressions","title":"What is the purpose of regular epressions?","text":"<p>It allows you to seach text and find infomation that you care about. </p>"},{"location":"System%20Admin/regex%20training/#what-is-the-basic-regex","title":"what is the basic regex","text":"<p>If you use a global flag it will allow you to match on anything that is in the string. If you take the global flag off, your regex will only match on the first time it finds that exact string. /at/g &lt; This will match any string part that has an at,</p> <p>The fat cat ran down the street. The cat was searching for a mouse to eat.  </p> Symbol What symbol means + Match at least one but it can match more than one character ? Match an optional character, or used to highlight a match as non-greedy. * Match zero or more . Match any single character, except for a new line \\ The backslash cancels anything that comes after it. us it with a period to match a period as appose to a wildcard period \\w Match any character \\W Match anything that is not a character \\s Match any form of white space \\S Match anything that is not a white space \\w{min,max} This will match on any word that is in the min and max numbers [any_character] This will match any character that is inside the brackets, you can do ranges here. any_character_1|any_character_2 This will search for the character on the left or ont the write. (Group) this will allow you to group portions of the regex. ^ The carrot signifies the start of a line. If you only do the carrot, it will match on the first word of the line. Also if used in brackets carrot acts like a null character. $ The dollar sign signifies the end of the line. If you only do the dollar sign it will only match on the last word ^$ Carrot Dollar sign will match on the start and the end of the line. (?&lt;=) This is called a positive look behind. (?&lt;!) This is called a negative look behind."},{"location":"System%20Admin/vim%20basics/","title":"Vim basics","text":"<p>What is VIM? Successor of VI or aka VI improved Vim is a command line text editor that is in most linux os's.</p> <p>What are the VIM modes - while vim is open type in  :h vim-modes  to view the different vim modes. - There are 7 basic vim modes   - normal mode &lt;&lt; need to know     - default starting mode     - access this mode from other modes by pressing ESC     - read the file     - accepts \"invisible\" commands     - Nothing shows up at the bottom of the screen in this mode   - visual mode &lt;&lt; need to know     - Enter visual mode with v from normal mode     - apply commands on the selections of text     - similar to clicking and dragging with a mouse to hight text     - ESC to normal mode     - You will see -- Visual -- at the bottom of the screen when you are in this mode.   - select mode    - insert mode &lt;&lt; need to know     - From normal mode you press \"i\" to get into insert mode     - This where text is edited normally     - ESC to normal mode     - You will see -- INSERT -- at the bottom of the screen when you are in this mode.   - command-line mode &lt;&lt; need to know     - Enter command-line mode with : from normal mode       - : {followed by text }     - Modify settings, save or quit the file     - Features such as search and replace or help menu     - ESC to normal mode     - You will see : at the bottom of the screen when you are in this mode.   - ex mode   - terminal-job mode</p> <p>Save a file - :w - :w newfilename   - Makes a copy of the file</p> <p>Close a file - :q (quit) - :wq (save and quit) - :q! (force quit) - ZZ (save if changed and quit)</p>"}]}